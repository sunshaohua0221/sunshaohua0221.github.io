<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Kafka | SSH</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="第1章Kafka概述1.1 定义Kafka是一个分布式的基于发布&#x2F;订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 1.2 消息队列1.2.1 传统消息队列的应用场景   使用消息队列的好处  解藕，允许你独立的扩展或修改两边的处理过程，只要确保他们遵守同样的接口约束。 可恢复性，系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka">
<meta property="og:url" content="https://sunshaohua0221.github.io/2022/03/02/Kafka/index.html">
<meta property="og:site_name" content="SSH">
<meta property="og:description" content="第1章Kafka概述1.1 定义Kafka是一个分布式的基于发布&#x2F;订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 1.2 消息队列1.2.1 传统消息队列的应用场景   使用消息队列的好处  解藕，允许你独立的扩展或修改两边的处理过程，只要确保他们遵守同样的接口约束。 可恢复性，系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://sunshaohua0221.github.io/2022/03/02/Kafka/MQ%E4%BC%A0%E7%BB%9F%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E4%B9%8B%E5%BC%82%E6%AD%A5%E5%A4%84%E7%90%86.png">
<meta property="og:image" content="https://sunshaohua0221.github.io/2022/03/02/Kafka/%E7%82%B9%E5%AF%B9%E7%82%B9.png">
<meta property="og:image" content="https://sunshaohua0221.github.io/2022/03/02/Kafka/%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F.png">
<meta property="og:image" content="https://sunshaohua0221.github.io/2022/03/02/Kafka/Kafka%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84.png">
<meta property="og:image" content="https://sunshaohua0221.github.io/2022/03/02/Kafka/Kafka%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="https://sunshaohua0221.github.io/2022/03/02/Kafka/Kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6.png">
<meta property="og:image" content="https://sunshaohua0221.github.io/2022/03/02/Kafka/index%E6%96%87%E4%BB%B6%E5%92%8Clog%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3.png">
<meta property="og:image" content="https://sunshaohua0221.github.io/2022/03/02/Kafka/ProducerRecord.png">
<meta property="og:image" content="https://sunshaohua0221.github.io/2022/03/02/Kafka/%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81.png">
<meta property="og:image" content="https://sunshaohua0221.github.io/2022/03/02/Kafka/acks=1%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E6%A1%88%E4%BE%8B.png">
<meta property="og:image" content="https://sunshaohua0221.github.io/2022/03/02/Kafka/acks=-1%E6%95%B0%E6%8D%AE%E9%87%8D%E5%A4%8D%E6%A1%88%E4%BE%8B.png">
<meta property="article:published_time" content="2022-03-02T06:03:24.000Z">
<meta property="article:modified_time" content="2022-03-02T06:03:24.000Z">
<meta property="article:author" content="ssh">
<meta property="article:tag" content="技术、生活">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://sunshaohua0221.github.io/2022/03/02/Kafka/MQ%E4%BC%A0%E7%BB%9F%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E4%B9%8B%E5%BC%82%E6%AD%A5%E5%A4%84%E7%90%86.png">
  
    <link rel="alternate" href="/atom.xml" title="SSH" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 6.0.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">SSH</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://sunshaohua0221.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Kafka" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/03/02/Kafka/" class="article-date">
  <time datetime="2022-03-02T06:03:24.000Z" itemprop="datePublished">2022-03-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Kafka
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第1章Kafka概述"><a href="#第1章Kafka概述" class="headerlink" title="第1章Kafka概述"></a>第1章Kafka概述</h1><h2 id="1-1-定义"><a href="#1-1-定义" class="headerlink" title="1.1 定义"></a>1.1 定义</h2><p>Kafka是一个<code>分布式</code>的基于<code>发布/订阅模式</code>的<code>消息队列</code>（Message Queue），主要应用于大数据实时处理领域。</p>
<h2 id="1-2-消息队列"><a href="#1-2-消息队列" class="headerlink" title="1.2 消息队列"></a>1.2 消息队列</h2><h3 id="1-2-1-传统消息队列的应用场景"><a href="#1-2-1-传统消息队列的应用场景" class="headerlink" title="1.2.1 传统消息队列的应用场景"></a>1.2.1 传统消息队列的应用场景</h3><p><img src="MQ%E4%BC%A0%E7%BB%9F%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E4%B9%8B%E5%BC%82%E6%AD%A5%E5%A4%84%E7%90%86.png">  </p>
<p><strong>使用消息队列的好处</strong></p>
<ol>
<li>解藕，允许你独立的扩展或修改两边的处理过程，只要确保他们遵守同样的接口约束。</li>
<li>可恢复性，系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</li>
<li>缓冲，有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</li>
<li>灵活性 &amp; 峰值处理能力，在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。异步通信，很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</li>
</ol>
<h3 id="1-2-1-消息队列的两种模式"><a href="#1-2-1-消息队列的两种模式" class="headerlink" title="1.2.1 消息队列的两种模式"></a>1.2.1 消息队列的两种模式</h3><ol>
<li><p>点对点模式（<code>一对一</code>，消费者主动拉取数据，消息收到后消息清除）</p>
<p>消息生产者生产消息发送到Queue 中，然后消息消费者从Queue 中取出并且消费消息。消息被消费以后，queue 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue 支持存在多个消费者， 但是对一个消息而言， 只会有一个消费者可以消费。</p>
<p><img src="%E7%82%B9%E5%AF%B9%E7%82%B9.png">  </p>
<p>发布/订阅模式（一对多，消费者消费数据之后消息不会清楚）</p>
<p>消息生产者（发布）将消息发布到 topic 中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。</p>
<p><img src="%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F.png"></p>
<p>1.3 Kafka基础架构</p>
<p><img src="Kafka%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84.png"></p>
</li>
<li><p><strong>Producer</strong> ：消息生产者，就是向 kafka broker 发消息的客户端；</p>
</li>
<li><p><strong>Consumer</strong> ：消息消费者，向 kafka broker 取消息的客户端；</p>
</li>
<li><p><strong>Consumer Group</strong> （<strong>CG</strong>）：消费者组，由多个 consumer 组成。<code>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响</code>。所有的消费者都属于某个消费者组，即<code>消费者组是逻辑上的一个订阅者</code>。</p>
</li>
<li><p><strong>Broker</strong> ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker可以容纳多个topic。</p>
</li>
<li><p><strong>Topic</strong> ：可以理解为一个队列，<code>生产者和消费者面向的都是一个topic</code>；</p>
</li>
<li><p><strong>Partition</strong>：为了实现扩展性，一个非常大的 topic 可以分布到多个broker（即服务器）上，<code>一个topic可以分为多个partition</code>，每个 partition 是一个有序的队列；</p>
</li>
<li><p><strong>Replica</strong>：副本，为保证集群中的某个节点发生故障时，<code>该节点上的 partition 数据不丢失，且kafka 仍然能够继续工作</code>，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 <strong>leader</strong> 和若干个 <strong>follower</strong>。</p>
</li>
<li><p><strong>leader</strong>：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。</p>
</li>
<li><p><strong>follower</strong>：每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 leader。</p>
</li>
</ol>
<h1 id="第2章Kafka快速入门"><a href="#第2章Kafka快速入门" class="headerlink" title="第2章Kafka快速入门"></a>第2章Kafka快速入门</h1><h1 id="第3章Kafka架构深入"><a href="#第3章Kafka架构深入" class="headerlink" title="第3章Kafka架构深入"></a>第3章Kafka架构深入</h1><h2 id="3-1-Kafka工作流程及文件存储机制"><a href="#3-1-Kafka工作流程及文件存储机制" class="headerlink" title="3.1 Kafka工作流程及文件存储机制"></a>3.1 Kafka工作流程及文件存储机制</h2><p><img src="Kafka%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png">  </p>
<p>Kafka 中消息是以 <strong>topic</strong> 进行分类的，生产者生产消息，消费者消费消息，都是面向 topic的。</p>
<p>topic 是逻辑上的概念，而 partition 是物理上的概念，每个 partition 对应于一个 log 文件，该 log 文件中存储的就是 producer 生产的数据。Producer 生产的数据会被不断追加到该log 文件末端，且每条数据都有自己的 offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个offset，以便出错恢复时，从上次的位置继续消费。</p>
<p><img src="Kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6.png">  </p>
<p>由于生产者生产的消息会不断追加到 log 文件末尾，为防止 log 文件过大导致数据定位效率低下，Kafka 采取了分片和索引机制，将每个 partition 分为多个 segment。每个 segment 对应两个文件——“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic 名称+分区序号。例如，first 这个 topic 有三个分区，则其对应的文件夹为 first- 0,first-1,first-2。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">00000000000000000000.index</span><br><span class="line">00000000000000000000.log</span><br><span class="line">00000000000000170410.index</span><br><span class="line">00000000000000170410.log</span><br><span class="line">00000000000000239430.index</span><br><span class="line">00000000000000239430.log</span><br></pre></td></tr></table></figure>

<p>index 和 log 文件以当前 segment 的第一条消息的 offset 命名。下图为 index 文件和 log文件的结构示意图。</p>
<p><img src="index%E6%96%87%E4%BB%B6%E5%92%8Clog%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3.png">  </p>
<p><code>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据</code>，索引文件中的元  数据指向对应数据文件中message 的物理偏移地址。</p>
<h2 id="3-2-Kafka生产者"><a href="#3-2-Kafka生产者" class="headerlink" title="3.2 Kafka生产者"></a>3.2 Kafka生产者</h2><h3 id="3-2-1-分区策略"><a href="#3-2-1-分区策略" class="headerlink" title="3.2.1 分区策略"></a>3.2.1 分区策略</h3><ol>
<li><p>分区的原因</p>
<ul>
<li><code>方便在集群中扩展</code>，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic又可以有多个 Partition 组成，因此整个集群就可以适应任意大小的数据了；</li>
<li><code>可以提高并发</code>，因为可以以Partition 为单位读写了。</li>
</ul>
</li>
<li><p>分区的原则</p>
<p>我们需要将 producer 发送的数据封装成一个 <strong>ProducerRecord</strong> 对象。</p>
<p><img src="ProducerRecord.png">  </p>
<ul>
<li>指明 partition 的情况下，直接将指明的值直接作为 partiton 值；</li>
<li>没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition数进行取余得到 partition 值；</li>
<li>既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（ 后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到partition值，也就是常说的 round-robin 算法。</li>
</ul>
</li>
</ol>
<h3 id="3-2-2-数据可靠性保证"><a href="#3-2-2-数据可靠性保证" class="headerlink" title="3.2.2 数据可靠性保证"></a>3.2.2 数据可靠性保证</h3><p><code>为保证 producer 发送的数据，能可靠的发送到指定的 topic，topic 的每个 partition 收到producer 发送的数据后，都需要向 producer 发送 ack（acknowledgement 确认收到），如果producer 收到 ack，就会进行下一轮的发送，否则重新发送数据。</code></p>
<p><img src="%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81.png"></p>
<ol>
<li><p>副本数据同步策略</p>
<table>
<thead>
<tr>
<th>方案</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>半数以上完成同步，就发送 <strong>ack</strong></td>
<td>延迟低</td>
<td>选举新的 leader  时，容忍 n 台节点的故障，需要 2n+1 个副  本</td>
</tr>
<tr>
<td>全部完成同步，才发送  <strong>ack</strong></td>
<td>选举新的 leader  时，容忍 n 台节点的故障，需要 n+1 个副  本</td>
<td>延迟高</td>
</tr>
</tbody></table>
<p>Kafka 选择了第二种方案，原因如下：</p>
<ul>
<li>同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1个副本，而Kafka 的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</li>
<li>虽然第二种方案的网络延迟会比较高，但网络延迟对 Kafka 的影响较小。</li>
</ul>
</li>
<li><p>ISR</p>
<p>采用第二种方案之后，设想以下情景：leader 收到数据，所有 follower 都开始同步数据， 但有一个 follower，因为某种故障，迟迟不能与 leader 进行同步，那 leader 就要一直等下去， 直到它完成同步，才能发送 ack。这个问题怎么解决呢？</p>
<p><code>Leader 维护了一个动态的 in-sync replica set (ISR)，意为和 leader 保持同步的 follower 集合。当 ISR 中的 follower 完成数据的同步之后，leader 就会给 follower 发送 ack。如果 follower长 时 间 未 向 leader 同 步 数 据 ， 则 该 follower 将 被 踢 出 ISR ， 该 时 间 阈 值 由</code><strong>replica.lag.time.max.ms</strong> <code>参数设定。Leader 发生故障之后，就会从 ISR 中选举新的 leader。</code></p>
</li>
<li><p>ack应答机制</p>
<p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失， 所以没必要等ISR 中的 follower 全部接收成功。</p>
<p>所以 Kafka 为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡， 选择以下的配置。</p>
<p><strong>acks</strong> 参数配置：</p>
<p><strong>acks:</strong></p>
<p>0：producer 不等待 broker 的 ack，这一操作提供了一个最低的延迟，broker 一接收到还没有写入磁盘就已经返回，当 broker 故障时有可能丢失数据；</p>
<p>1：producer 等待broker 的 ack，partition 的 leader 落盘成功后返回ack，如果在 follower同步成功之前leader 故障，那么将会丢失数据；</p>
<p><img src="acks=1%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E6%A1%88%E4%BE%8B.png"></p>
<p>-1（all）：producer 等待 broker 的 ack，partition 的 leader 和 follower 全部落盘成功后才返回 ack。但是如果在 follower 同步完成后，broker 发送 ack 之前，leader 发生故障，那么会造成数据重复。</p>
<p><img src="acks=-1%E6%95%B0%E6%8D%AE%E9%87%8D%E5%A4%8D%E6%A1%88%E4%BE%8B.png"></p>
</li>
<li><p>故障处理节</p>
<p><strong>LEO</strong>：指的是每个副本最大的 <strong>offset</strong>；</p>
<p><strong>HW</strong>：指的是消费者能见到的最大的 <strong>offset</strong>，<strong>ISR</strong> 队列中最小的 <strong>LEO</strong>。</p>
<p>（1） <strong>follower</strong> 故障</p>
<p>follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后，follower 会读取本地磁盘记录的上次的HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。等该 <strong>follower</strong> 的 <strong>LEO</strong> 大于等于该 <strong>Partition</strong> 的 <strong>HW</strong>，即 follower 追上 leader 之后，就可以重新加入 ISR 了。</p>
<p>（2） <strong>leader</strong> 故障</p>
<p>leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的数据一致性，其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 leader同步数据。</p>
<p>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p>
</li>
</ol>
<h3 id="3-2-3-Exactly-Once-语义"><a href="#3-2-3-Exactly-Once-语义" class="headerlink" title="3.2.3 Exactly Once 语义"></a>3.2.3 Exactly Once 语义</h3><p>​        将服务器的 ACK 级别设置为-1，可以保证 Producer 到 Server 之间不会丢失数据，即 At Least Once 语义。相对的，将服务器 ACK 级别设置为 0，可以保证生产者每条消息只会被发送一次，即At Most Once 语义。</p>
<p>​        At Least Once 可以保证数据不丢失，但是不能保证数据不重复；相对的，At Least Once 可以保证数据不重复，但是不能保证数据不丢失。但是，对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即 Exactly Once 语义。在 0.11 版本以前的 Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</p>
<p>​        0.11 版本的 Kafka，引入了一项重大特性：幂等性。所谓的幂等性就是指Producer 不论向 Server 发送多少次重复数据，Server 端都只会持久化一条。幂等性结合 At Least Once 语义，就构成了Kafka 的Exactly Once 语义。即：</p>
<p>​                                                <code>At Least Once + 幂等性 = Exactly Once</code></p>
<p>​        要启用幂等性，只需要将 Producer 的参数中 enable.idompotence 设置为 true 即可。Kafka 的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的 Producer 在初始化的时候会被分配一个 PID，发往同一 Partition 的消息会附带 Sequence Number。而Broker 端会对&lt;PID, Partition, SeqNumber&gt;做缓存，当具有相同主键的消息提交时，Broker 只会持久化一条。</p>
<p>​        但是PID 重启就会变化，同时不同的 Partition 也具有不同主键，所以幂等性无法保证跨分区跨会话的Exactly Once。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://sunshaohua0221.github.io/2022/03/02/Kafka/" data-id="clq7nrdut0004z59y4yb41pra" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/07/26/Java%E9%94%81%E6%9C%BA%E5%88%B6/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Java锁机制
        
      </div>
    </a>
  
  
    <a href="/2022/02/17/TiDB-SQL%E7%9A%84%E4%B8%80%E7%94%9F/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">TiDB-SQL的一生</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">七月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">三月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">二月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/07/26/Java%E9%94%81%E6%9C%BA%E5%88%B6/">Java锁机制</a>
          </li>
        
          <li>
            <a href="/2022/03/02/Kafka/">Kafka</a>
          </li>
        
          <li>
            <a href="/2022/02/17/TiDB-SQL%E7%9A%84%E4%B8%80%E7%94%9F/">TiDB-SQL的一生</a>
          </li>
        
          <li>
            <a href="/2020/12/03/MySQL%20JDBC%E7%9A%84queryTimeout%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91/">ThreadPoolExecutor的拒绝策略CallerRunsPolicy的一个潜在的大坑</a>
          </li>
        
          <li>
            <a href="/2020/08/31/TiDB-SQL%E7%9B%91%E6%8E%A7%E5%8F%8A%E5%85%B8%E5%9E%8B%E7%9A%84%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B/">TiDB SQL监控及典型的优化案例</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 ssh<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>