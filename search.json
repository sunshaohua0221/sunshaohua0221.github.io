[{"title":"Redis rehash","path":"/2023/12/31/redis-rehash/","content":"Redis键值对结构 HashTableRedis中有一个全局哈希表，该哈希表中保存所有的键值对，对于Hash表查找的操作的复杂度为O(1)。 Bucket哈希表中每一个元素称为哈希桶（Bucket），哈希桶中保存了键值对数据。 Entry用来保存键值对数据，保存的是Key、Value的指针值，通过对应的指针对Key、Value进行查找。 什么是rehashredis在项目中时常用来放缓存信息，由上面可知是由位桶组成的，随着缓存信息越来越大，这时候就需要对redis进行扩容。然而，之前已经存在的键值对是redis经过hash计算出的值存放在hash桶上，此时扩容需要对之前的键值对进行重新计算也就是rehash。 rehash步骤Redis其实有两个全局全局哈希表，一开始默认使用的是Hash Table0（ht[0]）来存储数据，而Hash Table1（ht[1]）并没有分配内存空间，随着Hash Table0中的元素越来越多时，Redis会进行rehash操作。 为ht[1]分配空间 在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始 在rehash进行期间，每次对字段执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性值增1 随着字典操作的不断执行，最终在某个时间点上，ht[0]上的所有键值对都会被rehash至ht[1]，这是程序将rehashidx的值设置为-1，表示rehash操作已完成 准备开始rehash rehash索引0上的键值对 rehash索引1上的键值对 rehash索引2上的键值对 rehash索引3上的键值对 rehash执行完毕 在进行渐进式rehash过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字段的删除、查找、更新等操作会在两个哈希表上进行，比如，在字典里查找一个键的话，先在ht[0]里进行查找，如果没找到，就会继续在ht[1]里进行查找。 另外，在渐进式rehash进行期间，新添加到字典里的键值对一律会保存到ht[1]里，而ht[0]不在进行任何添加操作，这一措施保证了ht[0]包含的键值对数量只减不增，并随着rehash操作的执行最终变成空表。"},{"title":"分布式事务","path":"/2023/12/27/分布式事务/","content":"分布式事务： 在分布式系统中一次操作需要由多个服务协同完成，这种由不同的服务之间通过网络协同完成的事务 分布式事务分类 刚性事务 强一致性 XA模型 满足CAP理论的CP 柔性事务 保证最终一致性，事务结束后在可接收的时间范围内，可能出现短暂的不一致，最终会达成一致性 满足CAP理论的AP，满足BASE理论 刚性事务（XA） 柔性事务 业务改造 无 有 回滚 支持 实现补偿接口 一致性 强一致 最终一致 隔离性 原生支持 实现资源锁定接口 并发性能 严重衰退 略微衰退 适合场景 短事务并发低 长事务高并发 刚性事务 满足传统事务特性，ACID（原子性、一致性、隔离性、持久性） 满足XA模型 XA规范中定义了分布式事务处理模型，包含了3种核心角色 AP：Application Program，应用程序，通过TM定义事务边界（事务开始与结束），并且访问事务边界内的资源 RM：Resource Managers，资源管理器，提供数据资源的操作、管理接口，保证数据的一致性和完整性，主要包括数据库、MQ系统 、文件系统等。 TM：Transaction Managers，事务管理器，是一个协调者的角色，负责管理全局事务，分配全局事务ID，监测事务的执行速度，并负责事务的提交、回滚、失败恢复等。 2PC（两阶段提交）是XA规范标准实现 实现过程： AP发起一个全局事务，并且创建一个全局事务ID TM发起prepare投票，RM对投票进行表决 RM都同意后，TM发起commit提交。其中任何一个prepare时不同意，TM都会发起rollback。 在commit过程中，发生宕机等异常，在服务重启后根据XA recover再次进行补偿，保证最终commit操作成功。 缺点 同步阻塞模型 数据库资源锁定时间过程 全局锁（隔离级别串行化），并发能力低 不适合长事务 在一些异常情况下会有问题，在commit之后，回复给TM的ack丢失了，这时会导致TM不知道commit到底是否成功了，从而衍生出了三阶段提交来解决这个问题。 XA 两阶段提交协议设计上是要像本地事务一样实现事务的 ACID 四个特性： 原子性：在 prepare 和 commit 阶段保证事务是原子性的。 一致性：XA 协议实现的是强一致性。 隔离性：XA 事务在完成之前一直持有资源的锁，所以可以做到写隔离。 持久性：基于本地事务实现，所以这一点没有问题。 柔性事务满足CAP理论的AP，满足BASE理论，柔性事务是对XA协议的妥协，它通过降低强一致性，从而减少数据库资源的锁定时间，提升系统可用性。典型的架构实现： TCC模型 Saga模型 TCCTCC介绍TCC（Try Confirm Cancel）是应用层的两阶段提交，完全交由业务端实现，每个业务都需要实现Try、Confirm、Cancel接口，所以对代码的侵入性强。 TCC执行流程TCC的执行流程分为两个阶段： 第一阶段：Try，业务系统做监测并预留资源（加锁或锁住资源），比如常见的下单，在Try阶段，不是真正的减库存，而是把下单的库存给锁住。 第二阶段：根据第一阶段的结果决定是执行Confirm还是Cancel。Confirm：执行真正的业务（执行业务，释放锁）Cancel：是对Try阶段预留资源的释放（出问题，释放锁） TCC如何保证最终一致性 TCC事务以Try为中心的，Confirm确认操纵和Cancel取消操纵都是围绕try展开的。因此，Try阶段中的操纵，其保障性是最好的，即使失败仍然有Cancel取消操纵将其执行结果取消。 Try阶段执行成功并执行Confirm阶段时，默认Confirm阶段是不能出错的，也就是说，Try成功，Confirm一定成功（TCC设计之初的定义）。 Confirm和Cancel阶段如果执行失败，由TCC框架进行补偿。 存在极低概率在CC环节彻底失败，如果有，则需要定时任务或人工介入。 TCC的注意事项 允许空回滚空回滚出现的原因是Try超时或者丢包，导致TCC第二阶段触发Cancel操作，此时事务参与者未收到Try，但是却收到Cancel请求 所以，Cancel实现时允许空回滚，也就是Cancel执行时如果发现没有对应的事务xid或主键时，需要返回回滚成功，让事务管理器任务已经回滚。 防悬挂控制悬挂指的是二阶段的 Cancel 比 一阶段的Try 操作先执行，出现该问题的原因是 Try 由于网络拥堵而超时，导致事务管理器生成回滚，触发 Cancel 接口，但之后拥堵在网络的 Try 操作又被资源管理器收到了，但是 Cancel 比 Try 先到。但按照前面允许空回滚的逻辑，回滚会返回成功，事务管理器认为事务已回滚成功，所以此时应该拒绝执行空回滚之后到来的 Try 操作，否则会产生数据不一致。因此我们可以在 Cancel 空回滚返回成功之前，先记录该条事务 xid 或业务主键，标识这条记录已经回滚过，Try 接口执行前先检查这条事务xid或业务主键是否已经标记为回滚成功，如果是则不执行 Try 的业务操作。 幂等控制由于网络原因或者重试操作都有可能导致Try-Confirm-Cancel3个操作的重复执行，所以使用TCC时要注意这三个操纵的幂等控制，通常我们可以使用事务xid或业务主键来判重。 TCC方案的优缺点 相较于XA事务机制，有以下优点：性能提升： 具体业务来实现，控制资源锁的粒度变小，不会锁定整个资源。数据最终一致性： 基于Confirm和Cancel的幂等性，保证事务最终完成或取消，保证事务的一致性。可靠性： 解决了XA协议的协调者单点故障问题，由主业务方发起并控制整个活动，业务活动管理器也变成多点，引入集群。 缺点：TCC的Try、Confirm、Cancel要在具体的业务来实现，业务耦合度较高，提高了开发成本。 Saga什么是Saga事务aga事务核心思想是将长事务拆分为多个本地短事务并依次正常执行，如果所有短事务均执行成功，那么分布式事务提交；如果出现某个参与者执行本地事务失败，则由Saga事务协调器根据相反顺序调用补偿操作，回滚已提交的参与者，使分布式事务回到最初始的状态。Saga事务基本协议如下： 每个Saga事务由一系列幂等的有序子序列（sub-transaction）Ti组成 每个Ti都有对应的幂等补偿动作Ci，补偿动作用于撤销Ti造成的结果与TCC事务补偿机制相比，TCC有一个预留的Try动作，相当于先存一个草稿，然后才提交，Saga没有预留动作，直接提交。 Saga的恢复策略对于异常事务，Saga提供了两种恢复策略，分别如下： 向后恢复（backward recovery）当执行事务失败时，补偿所有已完成的事务，是“一退到底”的方式，这种做法的效果是撤销掉之前所有成功的子事务，使得整个 Saga 的执行结果撤销。如下图： 从上图可知事务执行到了支付事务T3，但是失败了，因此事务回滚需要从C3,C2,C1依次进行回滚补偿，对应的执行顺序为：T1,T2,T3,C3,C2,C1。 向前恢复(forward recovery)：对于执行不通过的事务，会尝试重试事务，这里有一个假设就是每个子事务最终都会成功，这种方式适用于必须要成功的场景，事务失败了重试，不需要补偿。流程如下图： Saga事务的实现方式 命令协调式（Order Orchestrator）中央协调器（Orchestrator，简称OSO）以命令&#x2F;回复的方式与每项服务进行通信，全权负责告诉每个参与者做什么以及什么时候该做什么。整体流程如下图： 事务发起方的主业务逻辑请求 OSO 服务开启订单事务 OSO 向库存服务请求扣减库存，库存服务回复处理结果。 OSO 向订单服务请求创建订单，订单服务回复创建结果。 OSO 向支付服务请求支付，支付服务回复处理结果。 主业务逻辑接收并处理 OSO 事务处理结果回复。中央协调器 OSO 必须事先知道执行整个事务所需的流程，如果有任何失败，它还负责通过向每个参与者发送命令来撤销之前的操作来协调分布式的回滚，基于中央协调器协调一切时，回滚要容易得多，因为协调器默认是执行正向流程，回滚时只要执行反向流程即可。 事件编排（Event Choreographyo）命令协调方式基于中央协调器实现，所以有单点风险，但是事件编排方式没有中央协调器。事件编排的实现方式中，每个服务产生自己的事件并监听其他服务的事件来决定是否应采取行动。 在事件编排方法中，第一个服务执行一个事务，然后发布一个事件，该事件被一个或多个服务进行监听，这些服务再执行本地事务并发布（或不发布）新的事件。当最后一个服务执行本地事务并且不发布任何事件时，意味着分布式事务结束，或者它发布的事件没有被任何 Saga 参与者听到都意味着事务结束。 事务发起方的主业务逻辑发布开始订单事件。 库存服务监听开始订单事件，扣减库存，并发布库存已扣减事件。 订单服务监听库存已扣减事件，创建订单，并发布订单已创建事件。 支付服务监听订单已创建事件，进行支付，并发布订单已支付事件。 主业务逻辑监听订单已支付事件并处理。 如果事务涉及 2 至 4 个步骤，则非常合适使用事件编排方式，它是实现 Saga 模式的自然方式，它很简单，容易理解，不需要太多的代码来构建。 Saga事务的优缺点 命令协调设计的优缺点： 优点：服务之间关系简单，避免服务间循环依赖，因为 Saga 协调器会调用 Saga 参与者，但参与者不会调用协调器。程序开发简单，只需要执行命令&#x2F;回复(其实回复消息也是一种事件消息)，降低参与者的复杂性。易维护扩展，在添加新步骤时，事务复杂性保持线性，回滚更容易管理，更容易实施和测试。 缺点：中央协调器处理逻辑容易变得庞大复杂，导致难以维护。存在协调器单点故障风险。 事件编排设计的优缺点： 优点：避免中央协调器单点故障风险。当涉及的步骤较少服务开发简单，容易实现。 缺点：服务之间存在循环依赖的风险。当涉及的步骤较多，服务间关系混乱，难以追踪调测。 由于 Saga 模型没有 Prepare 阶段，因此事务间不能保证隔离性。当多个 Saga 事务操作同一资源时，就会产生更新丢失、脏数据读取等问题，这时需要在业务层控制并发，例如：在应用层面加锁，或者应用层面预先冻结资源。 MQ事务消息MQ事务消息的执行流程基于MQ的分布式事务方案本质上是对本地消息表的封装，整体流程与本地消息表一致，唯一不同的就是将本地消息表存在了MQ内部，而不是业务数据库中，如下图： 由于将本地消息表存在了MQ内部，那么MQ内部的处理尤为重要，下面主要基于 RocketMQ4.3 之后的版本介绍 MQ 的分布式事务方案 RocketMQ事务消息在本地消息表方案中，保证事务主动方发写业务表数据和写消息表数据的一致性是基于数据库事务，而 RocketMQ 的事务消息相对于普通 MQ提供了 2PC 的提交接口，方案如下： 正常情况：在事务主动方服务正常，没有发生故障的情况下，发消息流程如下： 步骤①：发送方向 MQ Server(MQ服务方)发送 half 消息 步骤②：MQ Server 将消息持久化成功之后，向发送方 ack 确认消息已经发送成功 步骤③：发送方开始执行本地事务逻辑 步骤④：发送方根据本地事务执行结果向 MQ Server 提交二次确认（commit 或是 rollback）。 最终步骤：MQ Server 如果收到的是 commit 操作，则将半消息标记为可投递，MQ订阅方最终将收到该消息；若收到的是 rollback 操作则删除 half 半消息，订阅方将不会接受该消息 异常情况：在断网或者应用重启等异常情况下，图中的步骤④提交的二次确认超时未到达 MQ Server，此时的处理逻辑如下： 步骤⑤：MQ Server 对该消息发起消息回查 步骤⑥：发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果 步骤⑦：发送方根据检查得到的本地事务的最终状态再次提交二次确认。 最终步骤：MQ Server基于 commit&#x2F;rollback 对消息进行投递或者删除。 MQ事务消息的优缺点 优点：相比本地消息表方案，MQ 事务方案优点是： 消息数据独立存储 ，降低业务系统与消息系统之间的耦合 吞吐量大于使用本地消息表方案 缺点： 一次消息发送需要两次网络请求(half 消息 + commit&#x2F;rollback 消息) 。 业务处理服务需要实现消息状态回查接口。 最大努力通知最大努力通知也称为定期校对，是对MQ事务方案的进一步优化。它在事务主动方增加了消息校对的接口，如果事务被动方没有接收到主动方发送的消息，此时可以调用事务主动方提供的消息校对的接口主动获取 在可靠消息事务中，事务主动方需要将消息发送出去，并且让接收方成功接收消息，这种可靠性发送是由事务主动方保证的；但是最大努力通知，事务主动方仅仅是尽最大努力（重试，轮询….）将事务发送给事务接收方，所以存在事务被动方接收不到消息的情况，此时需要事务被动方主动调用事务主动方的消息校对接口查询业务消息并消费，这种通知的可靠性是由事务被动方保证的。 所以最大努力通知适用于业务通知类型，例如微信交易的结果，就是通过最大努力通知方式通知各个商户，既有回调通知，也有交易查询接口。 各方案常见使用场景总结 2PC&#x2F;3PC：依赖于数据库，能够很好的提供强一致性和强事务性，但延迟比较高，比较适合传统的单体应用，在同一个方法中存在跨库操作的情况，不适合高并发和高性能要求的场景。 TCC：适用于执行时间确定且较短，实时性要求高，对数据一致性要求高，比如互联网金融企业最核心的三个服务：交易、支付、账务。 本地消息表&#x2F;MQ 事务：适用于事务中参与方支持操作幂等，对一致性要求不高，业务上能容忍数据不一致到一个人工检查周期，事务涉及的参与方、参与环节较少，业务上有对账&#x2F;校验系统兜底。 Saga 事务：由于 Saga 事务不能保证隔离性，需要在业务层控制并发，适合于业务场景事务并发操作同一资源较少的情况。Saga 由于缺少预提交动作，导致补偿动作的实现比较麻烦，例如业务是发送短信，补偿动作则得再发送一次短信说明撤销，用户体验比较差。所以，Saga 事务较适用于补偿动作容易处理的场景"},{"title":"maven中deploy命令报401的原因及解决方案","path":"/2023/12/26/maven-deploy-401/","content":"idea使用过程中有时候会出现deploy时候报401错误，如下图 原因一、pom 文件李配置的私服仓库地址和settings.xml里配置的用户名和密码没有匹配上 pom.xml里的仓库配置12345678910111213&lt;!--项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件jar等部署到远程仓库 --&gt;&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;releases&lt;/id&gt;&lt;!-- 此处id和settings.xml的id保持一致 --&gt; &lt;name&gt;Release Deploy&lt;/name&gt; &lt;url&gt;http://10.20.105.11:8081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt;&lt;!--构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素 --&gt; &lt;id&gt;snapshots&lt;/id&gt;&lt;!-- 此处id和settings.xml的id保持一致 --&gt; &lt;name&gt;Snapshot Deploy&lt;/name&gt; &lt;url&gt;http://10.20.105.11:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; 此时对应的setting.xml里的配置信息为123456789101112&lt;servers&gt; &lt;server&gt; &lt;id&gt;snapshots&lt;/id&gt;&lt;!-- 此处id和上面pom.xml的id保持一致 --&gt; &lt;username&gt;zhangsan&lt;/username&gt; &lt;password&gt;123456&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;releases&lt;/id&gt;&lt;!-- 此处id和上面pom.xml的id保持一致 --&gt; &lt;username&gt;zhangsan&lt;/username&gt; &lt;password&gt;123456&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt; 检查两者信息是否一致，就可以解决问题。如果还是报401问题，则可能是下面的原因。 原因二、idea中自定义的settings.xml配置没有生效"},{"title":"BASE理论","path":"/2023/12/25/BASE/","content":"摘自JavaGuide BASE简介BASE理论起源于2008年，由eBay的架构师Dan Pritchett在ACM上发表。BASE是Basically Available（基本可用）、Soft-state（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。BASE理论是对CAP中一致性C和可用性A权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于CAP定理逐渐演化而来的，它大大降低了我们对系统的要求。 BASE理论的核心思想即使无法做到强一致性，但每个应用都可以根据自身的业务特点，采用适当的方式来达到最终一致性。 也就是牺牲数据的一致性来满足系统的高可用性，系统中一部分数据不可用或者不一致时，仍需要保持系统的整体可用。 BASE理论本质上是对CAP的延伸和补充，更具体的说，是对CAP中的AP方案的一个补充。 为什么这么说呢&#x2F; CAP理论这节我们也说过了 如果系统没有发生“分区”的话，节点间的网络连接通信正常的话，也就不存在 P 了。这个时候，我们就可以同时保证 C 和 A 了。因此，如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”的话，我们要思考如何保证 CA 。 因此，AP方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。在分区故障恢复后，系统应该达到最终一致性，这一点其实就是BASE理论延伸的地方。 BASE理论三要素 基本可用基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。什么叫允许损失部分可用性呢？ 响应时间上的损失: 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。 系统功能上的损失：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。 软状态软状态指允许系统中的数据存在中间状态（CAP 理论中的数据不一致），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。 最终一致性最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 分布式一致性的 3 种级别： 强一致性：系统写入了什么，读出来的就是什么。 弱一致性：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。 最终一致性：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。业界比较推崇是最终一致性级别，但是某些对数据一致要求十分严格的场景比如银行转账还是要保证强一致性。 那实现最终一致性的具体方式是什么呢? 《分布式协议与算法实战》 中是这样介绍： 读时修复 : 在读取数据时，检测数据的不一致，进行修复。比如 Cassandra 的 Read Repair 实现，具体来说，在向 Cassandra 系统查询数据的时候，如果检测到不同节点的副本数据不一致，系统就自动修复数据。 写时修复 : 在写入数据，检测数据的不一致时，进行修复。比如 Cassandra 的 Hinted Handoff 实现。具体来说，Cassandra 集群的节点之间远程写数据的时候，如果写失败 就将数据缓存下来，然后定时重传，修复数据的不一致性。 异步修复 : 这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复。 比较推荐 写时修复，这种方式对性能消耗比较低。 总结ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。"},{"title":"CAP理论","path":"/2023/12/25/CAP/","content":"CAP简介CAP（CAP theorem）定理又被称作布鲁尔定理（Brewer’s theorem），是加州大学伯克利分校的计算机科学家埃里克·布鲁尔（Eric Brewer）在2000年的ACM PODC上提出的一个猜想。2002年，麻省理工学院的赛斯·吉尔伯特（Seth Gilbert）和南希·林奇（Nancy Lynch）发表了布鲁尔猜想的证明，使之成为分布式计算领域公认的一个定理。 CAP是Consistency（一致性）、Availability（可用性）、Partition Tolerance（分区容错性） 这三个单词首字母组合。 在一个分布式系统（指互相连接并共享数据的节点的集合）中，当涉及到读写操作时，只能同时满足一下三点中的两个： 一致性：所有节点访问同一份最新的数据副本。 可用性：非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。 分区容错性：分布式出现网络分区的时候，让能对外提供服务。 什么是网络分区？分布式系统中，多个节点之间的网络本来是连通的，但是因为某些故障（比如部分节点网络出现了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫网络分区。 不是所谓的”3选2”大部分人解释这一定律时，常常简单的表述为”一致性、可用性、分区容错性，这三者只能同时达到两个，不可能同时达到”。实际上这是一个非常有误导性的说法，而且在CAP理论诞生12年之后，CAP之父也在2012年重写了之前的论文。 当发生网络分区的时候，如果我们要继续提供服务，那么强一致性合可用性只能2选1。也就是说当网络分区之后P是前提，决定了P之后才有C和A的选择。也就是说分区容错性（Partition Tolerance）我们是必须要实现的。简而言之就是：CAP理论中分区容错性P是一定要满足的，在此基础上，只能满足可用性A或者一致性C。 因此，分布式系统理论上不可能选择CA架构，只能选择CP或者AP架构。比如ZooKeeper、HBase就是CP架构，Cassandra、Eureka就是AP架构，Nacos不仅支持CP也支持AP。 为啥不能选择CA架构呢？举个例子：若系统出现分区，系统中某个节点在进行写操作。为了保证C，必须要禁止其他节点的读写操作，这就和A发生冲突了。如果为了保证A，其他节点的读写操作正常的话，那就和C发生冲突了。 选择CP和AP的关键在于当前的业务场景，没有定论，比如对于需要确保强一致性的场景如银行一般会选择CP。 另外需要补充说明一点的是，如果网络分区正常的话，也就是说不需要保证P的时候，C和A能够同时保证。 CAP实际应用案例以注册中心来探讨一下CAP的实际应用，下图是Dubbo的架构图，其中注册中心（Registry）负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。 常见的可以作为注册中心的有：Zookeeper、Eureka、Nacos等。 Zookeeper保证的是CP。任何时刻对Zookeeper的读请求都能得到一致性的结果，但是，Zookeeper不保证每次请求的可用性，比如在Leader选举过程中或者半数以上的机器不可用的时候就是不可用的。 Eureka保证的则是AP。Eureka在设计的时候就是优先保证A（可用性）。在Eureka中不存在什么Leader节点，每个节点都是一样的、平等的。因此Eureka不会像Zookeeper那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况，Eureka保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了，只不过这个节点上的数据可能并不是最新的。 Nacos不仅支持CP也支持AP。 总结在进行分布式系统设计和开发时，我们不应该仅仅局限在 CAP 问题上，还要关注系统的扩展性、可用性等等在系统发生“分区”的情况下，CAP 理论只能满足 CP 或者 AP。要注意的是，这里的前提是系统发生了“分区”如果系统没有发生“分区”的话，节点间的网络连接通信正常的话，也就不存在 P 了。这个时候，我们就可以同时保证 C 和 A 了。总结：如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”的话，我们要思考如何保证 CA 。"},{"title":"Java锁机制","path":"/2022/07/26/Java锁机制/","content":"1.什么是锁在并发情况下，多个线程会对同一个资源进行争抢，那么可能会导致数据不一致的问题，为了解决这个问题很多编程语言都引入了锁机制，通过一种抽象的锁来对资源进行锁定 2. 锁机制是怎么设计的在谈锁之前先了解一些Java虚拟机内存结构的知识，JVM运行时内存结构主要包含了程序计数器、JVM栈、Native栈、堆、方法区，对于程序计数器、JVM栈、Native栈是线程私有的，对于这个区域的数据，不会出现线程竞争的问题，而堆、方法区中的数据被所有线程共享，其中Java堆中存放的是所有对象，方法区中存放着类信息、常量、静态变量等数据。所以当多个线程在竞争其中一些数据时，有可能会发生难以预料的异常情况，因此需要锁机制进行限制， 锁是一种抽象的概念，那么它在代码层面是究竟如何实现的呢？简单来说，在Java中，每个Object，也就是每个对象都拥有一把锁，这把锁存放在对象头中，锁中记录了当前对象被哪个线程所占用。 刚才提到了锁是存放在对象头中的，那么对象、对象头的结构分别是什么呢？先来看下对象的结构，Java对象包含了三个部分：对象头、实例数据、对齐填充字节，其中对齐填充字节是为了满足Java对象的大小必须是8比特的倍数这一条件设置的，对齐填充字节正如它的名字一样，是为了帮只对象来对齐而填充的一些无用字节，大可不必理会，实例数据就是你在初始化对象时，设定的属性和状态的内容，对象头则是要说的重点之一，它存放了一些对象本身的运行时信息，对象头包含了两部分，Mark Word和Class Point，相较于实例数据，对象头属于一些额外的存储开销，所以它被设计的极小来提高效率"},{"title":"Kafka","path":"/2022/03/02/Kafka/","content":"第1章Kafka概述1.1 定义Kafka是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 1.2 消息队列1.2.1 传统消息队列的应用场景 使用消息队列的好处 解藕，允许你独立的扩展或修改两边的处理过程，只要确保他们遵守同样的接口约束。 可恢复性，系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。 缓冲，有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。 灵活性 &amp; 峰值处理能力，在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。异步通信，很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。 1.2.1 消息队列的两种模式 点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除） 消息生产者生产消息发送到Queue 中，然后消息消费者从Queue 中取出并且消费消息。消息被消费以后，queue 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue 支持存在多个消费者， 但是对一个消息而言， 只会有一个消费者可以消费。 发布&#x2F;订阅模式（一对多，消费者消费数据之后消息不会清楚） 消息生产者（发布）将消息发布到 topic 中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。 1.3 Kafka基础架构 Producer ：消息生产者，就是向 kafka broker 发消息的客户端； Consumer ：消息消费者，向 kafka broker 取消息的客户端； Consumer Group （CG）：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。 Broker ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker可以容纳多个topic。 Topic ：可以理解为一个队列，生产者和消费者面向的都是一个topic； Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个 partition 是一个有序的队列； Replica：副本，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。 leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。 follower：每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 leader。 第2章Kafka快速入门第3章Kafka架构深入3.1 Kafka工作流程及文件存储机制 Kafka 中消息是以 topic 进行分类的，生产者生产消息，消费者消费消息，都是面向 topic的。 topic 是逻辑上的概念，而 partition 是物理上的概念，每个 partition 对应于一个 log 文件，该 log 文件中存储的就是 producer 生产的数据。Producer 生产的数据会被不断追加到该log 文件末端，且每条数据都有自己的 offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个offset，以便出错恢复时，从上次的位置继续消费。 由于生产者生产的消息会不断追加到 log 文件末尾，为防止 log 文件过大导致数据定位效率低下，Kafka 采取了分片和索引机制，将每个 partition 分为多个 segment。每个 segment 对应两个文件——“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic 名称+分区序号。例如，first 这个 topic 有三个分区，则其对应的文件夹为 first- 0,first-1,first-2。 12345600000000000000000000.index00000000000000000000.log00000000000000170410.index00000000000000170410.log00000000000000239430.index00000000000000239430.log index 和 log 文件以当前 segment 的第一条消息的 offset 命名。下图为 index 文件和 log文件的结构示意图。 “.index”文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元 数据指向对应数据文件中message 的物理偏移地址。 3.2 Kafka生产者3.2.1 分区策略 分区的原因 方便在集群中扩展，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic又可以有多个 Partition 组成，因此整个集群就可以适应任意大小的数据了； 可以提高并发，因为可以以Partition 为单位读写了。 分区的原则 我们需要将 producer 发送的数据封装成一个 ProducerRecord 对象。 指明 partition 的情况下，直接将指明的值直接作为 partiton 值； 没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition数进行取余得到 partition 值； 既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（ 后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到partition值，也就是常说的 round-robin 算法。 3.2.2 数据可靠性保证为保证 producer 发送的数据，能可靠的发送到指定的 topic，topic 的每个 partition 收到producer 发送的数据后，都需要向 producer 发送 ack（acknowledgement 确认收到），如果producer 收到 ack，就会进行下一轮的发送，否则重新发送数据。 副本数据同步策略 方案 优点 缺点 半数以上完成同步，就发送 ack 延迟低 选举新的 leader 时，容忍 n 台节点的故障，需要 2n+1 个副 本 全部完成同步，才发送 ack 选举新的 leader 时，容忍 n 台节点的故障，需要 n+1 个副 本 延迟高 Kafka 选择了第二种方案，原因如下： 同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1个副本，而Kafka 的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。 虽然第二种方案的网络延迟会比较高，但网络延迟对 Kafka 的影响较小。 ISR 采用第二种方案之后，设想以下情景：leader 收到数据，所有 follower 都开始同步数据， 但有一个 follower，因为某种故障，迟迟不能与 leader 进行同步，那 leader 就要一直等下去， 直到它完成同步，才能发送 ack。这个问题怎么解决呢？ Leader 维护了一个动态的 in-sync replica set (ISR)，意为和 leader 保持同步的 follower 集合。当 ISR 中的 follower 完成数据的同步之后，leader 就会给 follower 发送 ack。如果 follower长 时 间 未 向 leader 同 步 数 据 ， 则 该 follower 将 被 踢 出 ISR ， 该 时 间 阈 值 由replica.lag.time.max.ms 参数设定。Leader 发生故障之后，就会从 ISR 中选举新的 leader。 ack应答机制 对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失， 所以没必要等ISR 中的 follower 全部接收成功。 所以 Kafka 为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡， 选择以下的配置。 acks 参数配置： acks: 0：producer 不等待 broker 的 ack，这一操作提供了一个最低的延迟，broker 一接收到还没有写入磁盘就已经返回，当 broker 故障时有可能丢失数据； 1：producer 等待broker 的 ack，partition 的 leader 落盘成功后返回ack，如果在 follower同步成功之前leader 故障，那么将会丢失数据； -1（all）：producer 等待 broker 的 ack，partition 的 leader 和 follower 全部落盘成功后才返回 ack。但是如果在 follower 同步完成后，broker 发送 ack 之前，leader 发生故障，那么会造成数据重复。 故障处理节 LEO：指的是每个副本最大的 offset； HW：指的是消费者能见到的最大的 offset，ISR 队列中最小的 LEO。 （1） follower 故障 follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后，follower 会读取本地磁盘记录的上次的HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。等该 follower 的 LEO 大于等于该 Partition 的 HW，即 follower 追上 leader 之后，就可以重新加入 ISR 了。 （2） leader 故障 leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的数据一致性，其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 leader同步数据。 注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。 3.2.3 Exactly Once 语义​ 将服务器的 ACK 级别设置为-1，可以保证 Producer 到 Server 之间不会丢失数据，即 At Least Once 语义。相对的，将服务器 ACK 级别设置为 0，可以保证生产者每条消息只会被发送一次，即At Most Once 语义。 ​ At Least Once 可以保证数据不丢失，但是不能保证数据不重复；相对的，At Least Once 可以保证数据不重复，但是不能保证数据不丢失。但是，对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即 Exactly Once 语义。在 0.11 版本以前的 Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。 ​ 0.11 版本的 Kafka，引入了一项重大特性：幂等性。所谓的幂等性就是指Producer 不论向 Server 发送多少次重复数据，Server 端都只会持久化一条。幂等性结合 At Least Once 语义，就构成了Kafka 的Exactly Once 语义。即： ​ At Least Once + 幂等性 = Exactly Once ​ 要启用幂等性，只需要将 Producer 的参数中 enable.idompotence 设置为 true 即可。Kafka 的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的 Producer 在初始化的时候会被分配一个 PID，发往同一 Partition 的消息会附带 Sequence Number。而Broker 端会对&lt;PID, Partition, SeqNumber&gt;做缓存，当具有相同主键的消息提交时，Broker 只会持久化一条。 ​ 但是PID 重启就会变化，同时不同的 Partition 也具有不同主键，所以幂等性无法保证跨分区跨会话的Exactly Once。"},{"title":"TiDB-SQL的一生","path":"/2022/02/17/TiDB-SQL的一生/","content":"SQL的一生 从客户端的Socket读取一条SQL 获取一个token 从PD获取TSO（事务的时间戳） 使用Parser将SQL parse为AST 将AST compile为执行计划 Logical Optimizer Physical Optimizer Execute Plan 根据对应的执行计划，最底层的Executor会根据这条SQL处理的Key范围构建出多个要下发到TiKV的请求，并通过distsql的API将这些请求分发到TiKV TiKV对结果做一些处理（包括filter,limit等）后，将中间结果集反馈给TiDB TiDB进行一些表关联、聚合运算最终返回给Client TiKV收到请求后，会将请求分为两类： storage read pool执行引擎：负责主键和唯一索引点查 coprocessor执行引擎：其余的请求 如何定位slow queryslow query产生的原因 按组件划分 TiDB parse慢 complie慢，生成物理执行计划 get token慢，分配线程慢 执行计划不正确 PD 获取tso慢，每个SQL要获取时间戳的 TiKV 需要扫描大量的key，耗时久 coprocessor cpu打满，资源等待 读热点 slow query获取渠道 集群监控上的metrics信息 slow-query log，对标MySQL格式，支持市场上的MySQL慢查询分析工具 TiDB的慢查询SQL内存表 TiKV节点日志slow-query反查 TiDB - Parse Metrics 位置：TiDB-&gt;Executor-&gt;Parse Duration parse慢可能原因：TiDB节点CPU压力大 图例： TiDB - Compile Metrics 位置：TiDB-&gt;Executor-&gt;Compile Duration parse慢可能原因： TiDB节点CPU压力大 in子查询结果集多，跟参数tidb_opt_insuqquery_unfold有关(2.1) 这个参数控制in子查询执行计划的处理，设置为1的情况，会默认把in的子查询结果集当做一个常量返回给上一层做where条件的过滤，compile是要生成物理执行计划的，在执行计划时in的查询已经执行了，只在2.1有开关，默认关闭，3.0后没有这个参数 图例： TiDB - Get Token Duration Metrics 位置：TiDB-&gt;Server-&gt;Get Token Duration parse慢可能原因：token个数不足，需要调整token-limit 说明连接过多，token默认上限是1000，超过1000后，客户端或者前台需要等待，如果这个等待比较长，并且连接数也超过上限了，就可以适当的调整这个参数，或者加TiDB节点 图例： PD - tso 位置：PD-&gt;Grpc-&gt;99% completed_cmd_duration_seconds-&gt;txn 可能慢的原因： PD Leader切换 PD Leader节点异常，包括cpu、磁盘等。 图例： TIKV - Grpc Duration Metrics 位置：TiKV-&gt;Grpc-&gt;Coprocessor 可能慢的原因： 需要大量扫描的key，某个SQL扫了大量的key Coprocessor CPU打满，造成资源等待 图例： TIKV - Coprocessor Cpu 位置：TiKV-&gt;Thead Cpu-&gt;Coprocessor Cpu 可能慢的原因： 大量扫描的key，将cpu资源占满 读热点，造成cpu资源等待 图例： 慢查询排查技能 - slow query log#Time：2019-04-25-15:19:33.26029 +0800 –记录了sql执行完成的时间，不是开始的时间 #Txn_start_ts：407942403346923524 –事务开始的时间戳 #User：&#x72;&#x6f;&#111;&#x74;&#64;&#49;&#x32;&#x37;&#46;&#x30;&#46;&#x30;&#x2e;&#x31; #Conn_ID：1 #Query_time：2.632671582 –sql整体执行时间 #Process_time：0.079 Wait_time：0.009 Backoff_time：0.1 Request_count：8 Total_keys：20008 Process_keys：20000 –TiKV相关时间 #DB：test #Index_ids：[1] –TiDB，生成计划用到的索引 #Is_internal：false #Digest：edb16a8f28d9c48790925fd1c868fdae3feb49bc58481dda7df228625a5ba6e1 #Stats：t_wide:407941920305971202,t_slim:pseudo –TiDB #Cop_proc_avg：0.009875 Cop_proc_p90：0.018 Cop_proc_max：0.018 Cop_proc_addr：127.0.0.1:22160 –详细Cop信息 #Cop_wait_avg：0.001125 Cop_wait_p90：0.002 Cop_wait_max：0.002 Cop_wait_addr：127.0.0.1:24160 #Mem_max：195349 –TiDB 内存使用大小 select count(1) from t_slim,t_wide where t.clim.c0&gt;t.wide.c0 and t.slim.c1&gt;t.wide.c1 and t_wide.c0 &gt; 5000; Red color is related with TiDB Blue color is related with TiKV&#x2F;Coprocessor 慢查询排查技能 - 内存表INFOMATION_SCHEMA: select * from slow_query order by query_time desc, total_keys&#x2F;process_keys\\G; slow_query的字段值跟slow query log是对应的 slow log相关参数 slow-threshold 参数含义：输出慢sql的耗时阈值，单位ms，静态参数，需要重启TiDB SERVER生效 建议值：在OLTP系统，建议设置50ms左右，OLTP系统SQL一版有以下特点：SQL短小、单次运行时间短、执行次数多；OLAP系统可以适当放大点。 query-log-max-len 参数含义：日志记录的SQL长度，超过这个长度会截断输出，单位为字符，静态参数，需要重启TiDB SERVER生效 建议值：4096 tidb_slow_query_file 参数含义：日志记录的SQL长度，超过这个长度会截断输出，单位为字符，静态参数，需要重启TiDB SERVER生效 建议值：慢查询日志的文件名，默认值为tidb_slow.log，可以存储300M内容，动态参数，可以通过会话变量生效 建议值：tidb_slow.log 300M以后会重新生成一个文件，所以如果要定位某一段时间的slow log，需要设置该环境变量，TiDB通过session变量tidb_slow_query_file控制查询 INFOMATION_SCHEMA.SLOW_QUERY时要读取和解析的文件，可通过修改session变量的值来查询其他慢查询日志文件的内容 用SQL从多个维度查询slow log表查询INFOMATION_SCHEMA.SLOW_QUERY TiKV日志反查slow log在某个SQL执行导致的TiKV cpu异常高的场合下，使用TiKV可以快速的定位问题SQL TiKV日志中记录了slow-query的几个关键信息： ipv4：发出请求的TiDB地址，通过该地址可以确定SQL在哪个TiDB节点执行 start_ts：事务的start_ts，通过start_ts反查slow log，快速定位问题SQL，不太适合特别频繁的查询场景，start_ts很多，很难查 table_id：查询的那张表，可以通过information_schema.tables的tidb_table_id反查表名 使用方法总结 通过监控的相关metrics可以获取到TiDB集群的整体运行情况，比如某些TiKV节点CPU高不高等，对于定位慢查询来说可以有一个初步的认知，用metrics来判断哪些时间段存在问题，可能存在哪些问题 slow query log及slow log内存表，可以从整体上观察SQL运行情况，比如SQL执行花了多长时间，执行多少次，哪些SQL最耗时，哪些SQL占用资源最多等等 但是slow log内存表还存在一定的局限性，因为每个TiDB有自己的slow log且slow log file到达300M后还会切换，所以使用起来还是有一定的局限性 TiKV日志能够快速定位问题SQL，对于执行一次或几次的的大SQL来说，非常容易定位问题，但是如果单次执行快但是执行频率高的SQL来说，查看TiKV日志还是相对比较麻烦 综上所述，结合的使用三个工具能比较快速定位问题SQL AP场景加速相关并发参数扫描key数量比较多 tidb_distsql_scan_concurrency 这个变量用来设置scan操作的并发度，对于AP类应用，最大建议值不要超过所有TiKV节点的CPU核数 tidb_index_serial_scan_concurrency 这个变量用来设置顺序scan操作的并发度 tidb_index_lookup_scan_concurrency 这个变量用来设置index lookup操作的并发度 tidb_index_lookup_join_concurrency 这个变量用来设置index lookup join算法的并发度 tidb_hash_join_concurrency 这个变量用来设置hash join算法的并发度 SQL优化案例TiDB SQL优化需要注意的点 where col1条件or col2条件，在TiDB中无法使用多个索引即MySQL的index merge功能，会导致全表扫描，可以转换为from xxx where col1 union from xxx where col2，这样就可以同时使用col1索引和col2索引。注意：需要注意本身结果集是否有重复数据，若有重复数据union和or无法等价转换 index join的被驱动表，不能有函数处理的过滤条件，类似where year(xxx)&#x3D;’2020’，尽量不要在过滤条件增加对列的函数处理，（现在还不支持函数索引，4.0后会支持） 其余与通用数据库SQL一样，需要注意尽量减少not in，not exits使用，尽量用表关联 亮点：TiDB支持null及like ‘abc%’使用索引，!&#x3D;xxx在TiDB也能转换为索引范围扫描，可以转换为[-inf,xxx),(xxx,+inf]，在某些特定场景比较有意义"},{"title":"ThreadPoolExecutor的拒绝策略CallerRunsPolicy的一个潜在的大坑","path":"/2020/12/03/MySQL JDBC的queryTimeout的一个坑/","content":"https://blog.csdn.net/xieyuooo/article/details/39898449?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control"},{"title":"TiDB SQL监控及典型的优化案例","path":"/2020/08/31/TiDB-SQL监控及典型的优化案例/","content":"TiDB读请求的执行流程SQL的一生 从客户端的Socket读取一条SQL 获取一个token 从PD获取TSO（事务的时间戳） 使用Parser将SQL parse为AST 将AST compile为执行计划 Logical Optimizer Physical Optimizer Execute Plan 根据对应的执行计划，最底层的Executor会根据这条SQL处理的Key范围构建出多个要下发到TiKV的请求，并通过distsql的API将这些请求分发到TiKV TiKV对结果做一些处理（包括filter,limit等）后，将中间结果集反馈给TiDB TiDB进行一些表关联、聚合运算最终返回给Client TiKV收到请求后，会将请求分为两类： storage read pool执行引擎：负责主键和唯一索引点查 coprocessor执行引擎：其余的请求 如何定位slow queryslow query产生的原因 按组件划分 TiDB parse慢 complie慢，生成物理执行计划 get token慢，分配线程慢 执行计划不正确 PD 获取tso慢，每个SQL要获取时间戳的 TiKV 需要扫描大量的key，耗时久 coprocessor cpu打满，资源等待 读热点 slow query获取渠道 集群监控上的metrics信息 slow-query log，对标MySQL格式，支持市场上的MySQL慢查询分析工具 TiDB的慢查询SQL内存表 TiKV节点日志slow-query反查 TiDB - Parse Metrics 位置：TiDB-&gt;Executor-&gt;Parse Duration parse慢可能原因：TiDB节点CPU压力大 图例： TiDB - Compile Metrics 位置：TiDB-&gt;Executor-&gt;Compile Duration parse慢可能原因： TiDB节点CPU压力大 in子查询结果集多，跟参数tidb_opt_insuqquery_unfold有关(2.1) 这个参数控制in子查询执行计划的处理，设置为1的情况，会默认把in的子查询结果集当做一个常量返回给上一层做where条件的过滤，compile是要生成物理执行计划的，在执行计划时in的查询已经执行了，只在2.1有开关，默认关闭，3.0后没有这个参数 图例： TiDB - Get Token Duration Metrics 位置：TiDB-&gt;Server-&gt;Get Token Duration parse慢可能原因：token个数不足，需要调整token-limit 说明连接过多，token默认上限是1000，超过1000后，客户端或者前台需要等待，如果这个等待比较长，并且连接数也超过上限了，就可以适当的调整这个参数，或者加TiDB节点 图例： PD - tso 位置：PD-&gt;Grpc-&gt;99% completed_cmd_duration_seconds-&gt;txn 可能慢的原因： PD Leader切换 PD Leader节点异常，包括cpu、磁盘等。 图例： TIKV - Grpc Duration Metrics 位置：TiKV-&gt;Grpc-&gt;Coprocessor 可能慢的原因： 需要大量扫描的key，某个SQL扫了大量的key Coprocessor CPU打满，造成资源等待 图例： TIKV - Coprocessor Cpu 位置：TiKV-&gt;Thead Cpu-&gt;Coprocessor Cpu 可能慢的原因： 大量扫描的key，将cpu资源占满 读热点，造成cpu资源等待 图例： 慢查询排查技能 - slow query log#Time：2019-04-25-15:19:33.26029 +0800 –记录了sql执行完成的时间，不是开始的时间 #Txn_start_ts：407942403346923524 –事务开始的时间戳 #User：&#114;&#x6f;&#x6f;&#x74;&#x40;&#x31;&#50;&#x37;&#x2e;&#x30;&#x2e;&#48;&#46;&#49; #Conn_ID：1 #Query_time：2.632671582 –sql整体执行时间 #Process_time：0.079 Wait_time：0.009 Backoff_time：0.1 Request_count：8 Total_keys：20008 Process_keys：20000 –TiKV相关时间 #DB：test #Index_ids：[1] –TiDB，生成计划用到的索引 #Is_internal：false #Digest：edb16a8f28d9c48790925fd1c868fdae3feb49bc58481dda7df228625a5ba6e1 #Stats：t_wide:407941920305971202,t_slim:pseudo –TiDB #Cop_proc_avg：0.009875 Cop_proc_p90：0.018 Cop_proc_max：0.018 Cop_proc_addr：127.0.0.1:22160 –详细Cop信息 #Cop_wait_avg：0.001125 Cop_wait_p90：0.002 Cop_wait_max：0.002 Cop_wait_addr：127.0.0.1:24160 #Mem_max：195349 –TiDB 内存使用大小 select count(1) from t_slim,t_wide where t.clim.c0&gt;t.wide.c0 and t.slim.c1&gt;t.wide.c1 and t_wide.c0 &gt; 5000; Red color is related with TiDB Blue color is related with TiKV&#x2F;Coprocessor 慢查询排查技能 - 内存表INFOMATION_SCHEMA: select * from slow_query order by query_time desc, total_keys&#x2F;process_keys\\G; slow_query的字段值跟slow query log是对应的 slow log相关参数 slow-threshold 参数含义：输出慢sql的耗时阈值，单位ms，静态参数，需要重启TiDB SERVER生效 建议值：在OLTP系统，建议设置50ms左右，OLTP系统SQL一版有以下特点：SQL短小、单次运行时间短、执行次数多；OLAP系统可以适当放大点。 query-log-max-len 参数含义：日志记录的SQL长度，超过这个长度会截断输出，单位为字符，静态参数，需要重启TiDB SERVER生效 建议值：4096 tidb_slow_query_file 参数含义：日志记录的SQL长度，超过这个长度会截断输出，单位为字符，静态参数，需要重启TiDB SERVER生效 建议值：慢查询日志的文件名，默认值为tidb_slow.log，可以存储300M内容，动态参数，可以通过会话变量生效 建议值：tidb_slow.log 300M以后会重新生成一个文件，所以如果要定位某一段时间的slow log，需要设置该环境变量，TiDB通过session变量tidb_slow_query_file控制查询 INFOMATION_SCHEMA.SLOW_QUERY时要读取和解析的文件，可通过修改session变量的值来查询其他慢查询日志文件的内容 用SQL从多个维度查询slow log表查询INFOMATION_SCHEMA.SLOW_QUERY TiKV日志反查slow log在某个SQL执行导致的TiKV cpu异常高的场合下，使用TiKV可以快速的定位问题SQL TiKV日志中记录了slow-query的几个关键信息： ipv4：发出请求的TiDB地址，通过该地址可以确定SQL在哪个TiDB节点执行 start_ts：事务的start_ts，通过start_ts反查slow log，快速定位问题SQL，不太适合特别频繁的查询场景，start_ts很多，很难查 table_id：查询的那张表，可以通过information_schema.tables的tidb_table_id反查表名 使用方法总结 通过监控的相关metrics可以获取到TiDB集群的整体运行情况，比如某些TiKV节点CPU高不高等，对于定位慢查询来说可以有一个初步的认知，用metrics来判断哪些时间段存在问题，可能存在哪些问题 slow query log及slow log内存表，可以从整体上观察SQL运行情况，比如SQL执行花了多长时间，执行多少次，哪些SQL最耗时，哪些SQL占用资源最多等等 但是slow log内存表还存在一定的局限性，因为每个TiDB有自己的slow log且slow log file到达300M后还会切换，所以使用起来还是有一定的局限性 TiKV日志能够快速定位问题SQL，对于执行一次或几次的的大SQL来说，非常容易定位问题，但是如果单次执行快但是执行频率高的SQL来说，查看TiKV日志还是相对比较麻烦 综上所述，结合的使用三个工具能比较快速定位问题SQL AP场景加速相关并发参数扫描key数量比较多 tidb_distsql_scan_concurrency 这个变量用来设置scan操作的并发度，对于AP类应用，最大建议值不要超过所有TiKV节点的CPU核数 tidb_index_serial_scan_concurrency 这个变量用来设置顺序scan操作的并发度 tidb_index_lookup_scan_concurrency 这个变量用来设置index lookup操作的并发度 tidb_index_lookup_join_concurrency 这个变量用来设置index lookup join算法的并发度 tidb_hash_join_concurrency 这个变量用来设置hash join算法的并发度 SQL优化案例TiDB SQL优化需要注意的点 where col1条件or col2条件，在TiDB中无法使用多个索引即MySQL的index merge功能，会导致全表扫描，可以转换为from xxx where col1 union from xxx where col2，这样就可以同时使用col1索引和col2索引。注意：需要注意本身结果集是否有重复数据，若有重复数据union和or无法等价转换 index join的被驱动表，不能有函数处理的过滤条件，类似where year(xxx)&#x3D;’2020’，尽量不要在过滤条件增加对列的函数处理，（现在还不支持函数索引，4.0后会支持） 其余与通用数据库SQL一样，需要注意尽量减少not in，not exits使用，尽量用表关联 亮点：TiDB支持null及like ‘abc%’使用索引，!&#x3D;xxx在TiDB也能转换为索引范围扫描，可以转换为[-inf,xxx),(xxx,+inf]，在某些特定场景比较有意义"},{"title":"SQL诊断优化-持续更新","path":"/2020/07/20/SQL优化/","content":"Explain诊断Explain各参数的含义如下： 列名 说明 id 执行编号，标识select所属的行，如果语句中没有子查询或者关联查询，只有唯一的select，执行编号显示1，否则，内层的select语句一般会顺序编号，对应于其在原始语句的位置 select_key 显示本行是简单或者复杂select，如果查询有任何复杂的子查询，则最外层标记为PRIMARY（DERIVED、UNION、UNION RESULT） table 访问引用哪个表 type 数据访问&#x2F;读取操作类型（All、index、range、ref、eq_ref、const&#x2F;system、NULL） possible_keys 揭示哪一些索引可能有利于高效的查找 key 显示mysql实际决定采用哪个索引来优化查询 key_len 显示mysql在索引里使用的字节数 ref 显示了之前的表在key列记录的索引中查找值所用的列或常量 rows 为了找到所需要的行而需要读取的行数、估算值 Extra 额外信息，如using index、filesort等 select_type常见类型及其含义 SIMPLE：不包含子查询或者UNION操作的查询 PRIMARY：查询中如果包含任何子查询，那么最外层的查询被标记为PRIMARY SUBQUERY：子查询中第一个SELECT DEPENDENT SUBQUERY：子查询中的第一个SELECT，取决于外部查询 UNION：UNION操作的第二个或者之后的查询 DEPENDENT UNION：UNION操作的第二个或者之后的查询，取决于外部查询 UNION RESULT：UNION产生的结果集 DERIVED：出现在FROM子句中子查询 type常见类型及其含义 system：这是const类型的一个特例，只会出现在待查询的表只有一行数据的情况下 consts：常出现在主键或唯一索引与常量值进行比较的场景下，此时查询性能最优 eq_ref：当连接使用的是完整的索引并且是PRIMARY KEY或UNIQUE NOT NULL INDEX时使用它 ref：当连接使用的是前缀索引或连接条件不是PRIMARY KEY或UNIQUE INDEX时则使用它 ref_or_null：类似于ref的查询，但是附加了对NULL值列的查询 index_merge：该连接类型表示使用了索引进行合并优化 rang：使用索引进行范围扫描，常见于between、&gt;、&lt;这样的查询条件 index：索引连接类型与ALL相同，只是扫描的是索引树，通常出现在索引是该查询的覆盖索引的情况 ALL：全表扫描，效率最差的查找方式 阿里编码规范要求：至少要达到range级别，要求是ref级别，如果可以是consts最好 key列实际在查询中是否使用到索引标志字段 Extra列Extea列主要用于显示额外信息，常见信息及含义如下： Using where：MySQL服务器会在存储引擎检索行后再进行过滤 Using filesort：通常出现在GROUP BY或GROUP BY语句中，且排序或分组没有基于索引，此时需要使用文件在内存中排序，因为使用索引排序的性能好于使用文件排序，所以出现这种情况就可以考虑通过添加索引进行优化 Using index：使用了覆盖索引进行查询，此时不需要访问表，从索引中就可以获取到所需要的全部数据 Using index condition：查找使用了索引，但需要回表查询数据 Using temporary：标识需要使用临时表来处理查询，常出现GROUP BY或者GROUP BY语句中 SQL优化深度分页12-- 反例select * from table where 条件 limit 1000000, 10 MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时候，效率就特别低下 12-- 正例select a.* from table a, (select id from table where 条件 limit 1000000, 10) b where a.id = b.id 该方案的核心逻辑即聚簇索引，再不通过回表的情况下，快速拿到指定偏移量数据主键的id，然后利用聚簇索引进行回表查询，此时总量仅为10条，效率很高 1234567891011-- 其他思路-- id是连续的SELECT * from table WHERE id between 1000000 and 1000010;-- id不连续select * from table where id &gt;= (select id from table WHERE 条件 limit 1000000,1) limit 10-- 滚动查询，属性lastBatchMaxId存放了本次查询结果集中的最大id，开始于0，同时它也是下一批查询的起始id，直到返回空列表才退出死循环，适合大量数据导出等操作，select * from table where id &gt; #&#123;lastBatchMaxId&#125; order by id asc limit 10-- order by id desc怎么滚动查询？？？-- 第一次id起始为0，后面属性lastBatchMaxId存放了本次查询结果集中的最小id，是下一批查询的起始id，直到返回空列表才退出死循环select * from table where id &gt; 0 order by id desc limit 10select * from table where id &lt; #&#123;lastBatchMaxId&#125; order by id desc limit 10"},{"title":"String.valueOf慎用","path":"/2020/07/10/String.valueOf慎用/","content":"Java API中String.valueOf(Object obj)方法，当传入的参数为一个引用，并且引用为null时，方法会返回字符串&quot;null&quot;，这样就会引发一些你意向不到的”血案” jdk1.8.0_181中String.valueOf(Object obj)源码： 123456789101112/** * Returns the string representation of the &#123;@code Object&#125; argument. * * @param obj an &#123;@code Object&#125;. * @return if the argument is &#123;@code null&#125;, then a string equal to * &#123;@code &quot;null&quot;&#125;; otherwise, the value of * &#123;@code obj.toString()&#125; is returned. * @see java.lang.Object#toString() */public static String valueOf(Object obj) &#123; return (obj == null) ? &quot;null&quot; : obj.toString();&#125; 但当你用main方法验证时，又出现了NPE，What？ 123456789public static void main(String[] args) &#123; System.out.println(String.valueOf(null));&#125;Caused by: java.lang.NullPointerException\tat java.lang.String.&lt;init&gt;(String.java:166)\tat java.lang.String.valueOf(String.java:3008)\tat com.jcloud.billing.operation.Test.main(Test.java:21)\t... 5 more 点进方法后，发现调的是这个： 12345678910111213/** * Returns the string representation of the &#123;@code char&#125; array * argument. The contents of the character array are copied; subsequent * modification of the character array does not affect the returned * string. * * @param data the character array. * @return a &#123;@code String&#125; that contains the characters of the * character array. */public static String valueOf(char data[]) &#123; return new String(data);&#125; 这是两个问题： 1、String.valueOf(Object obj)，如果obj为null，则返回”null”这没什么好说的，因为源码就是这样写的，当你使用这个方法时，只需要特别注意一下返回值的判断，不是if(str == null)，而是if(str.equals(&quot;null&quot;)) 另外一点也体现出看源码的重要性，所以以后再调用任何API时都养成看源码的好习惯 2、System.out.println(String.valueOf(null))为什么会走到String valueOf(char data[])，而不是String.valueOf(Object obj)？看下String类库，有如下几种valueOf方法： 其中红色框中都是基本类型，null不是基本类型，能接受String.valueOf(null)的只有蓝色框中的方法，因为char[]比Object更精确，所以选择了String.valueOf(char[]) 何谓精确：这两个都能接受null的参数，这种情况下，java的重载会选取其中更精确的一个，所谓精确，比如有重载方法A和B，如果方法A入参是方法B入参的子集，则A比B更精确，换句话说就是char[]是Object的子集，毕竟Object是老大，当直接传null时会选择String.valueOf(char[])"},{"title":"Spring事务传播机制实战","path":"/2020/05/11/Spring事务传播机制实战/","content":"背景前段时间项目中做了一次大升级，其中包括数据库分库，由于分了库，原来的单库事务就变成了跨库事务，所以用到了分布式事务，引入了阿里开源的seata；由于业务的特殊性，是属于定点执行任务，在某一时间集中处理业务，所以在压力测试时，seata-server端由于事务并发量大导致seata-server的表有死锁问题，一直重试。显然不可接受，所以决定暂时舍弃seata，还是采用Spring的事务来实现跨库事务。虽然也达到了目的，但如果跨太多个库，还是不建议用Spring事务来解决，可能会造成数据不一致的情况。 Spring事务失效的原因(事务生效的条件)经常犯的错误： 方法不是public的，@Transactional作用于public方法上才会生效，如果方法不是public，能编译过能正常运行，但事务不生效，经常发生 类自身调用，同一个类的方法A调用方法B，方法B上有事务注解，事务不会生效，因为自身调用没用经过Spring代理类，默认只有在外部调用时才会生效，经常发生 异常被吃了，或者异常类型错误，Spring事务默认回滚的是RuntimeException，如果想触发其他异常回滚需要在注解上配置一下 1@Transactional(rollbackFor = Exception.class) 这个配置仅限于 Throwable 异常类及其子类 其他错误： 没有被Spring管理，类没有加注解@Service或者其他 数据源没有配置数据管理器 数据库引擎不支持事务，比如MyISAM 为什么会有传播机制Spring对事务的控制，是使用aop切面实现的，我们不用关心事务的开始、提交、回滚，只需要在方法上加上注解@Transactional即可，那这时候就有问题了： 场景1：serviceA方法调用serviceB方法，但两个方法都有事务，这个时候如果serviceB方法异常，是让serviceB方法提交，还是两个一起回滚； 场景2：serviceA方法调用serviceB方法，只有serviceA方法加了事务，serviceB方法是否也要加入serviceA方法的事务，如果serviceB方法异常，是否回滚serviceA； 场景3：serviceA方法调用serviceB方法，两者都有事务，serviceB正常执行完，但serviceA异常，是否需要回滚serviceB； 传播机制类型PROPAGATION_REQUIRED(默认) 支持当前事务，如果当前没有事务，则新建事务 如果当前存在事务，则加入当前事务，合并为一个事务 REQUIRES_NEW 新建事务，如果当前存在事务，则把当前事务挂起 这个类型，是独立提交事务，不受调用者的事务影响，父级异常，也不影响提交 NESTED 如果当前存在事务，它将成为父级事务的一个子事务，方法结束后并没有提交，只有等父级事务结束才提交 如果当前没有事务，则新建事务 如果它异常，父级可以捕获它的异常而不进行回滚，正常提交 但如果父级异常，它必回滚，这就是和REQUIRES_NEW的区别 SUPPORTS 如果当前存在事务，则加入事务 如果当前不存在事务，则以非事务方式运行，这个和没写没有区别 NOT_SUPPORTED 以非事务方式运行 如果当前存在事务，则把当前事务挂起 MANDATORY 如果当前存在事务，则运行在当前事务中 如果当前不存在事务，则抛出异常，也即父级方法必须有事务 NEVER 以非事务方式运行，如果当前存在事务，则抛出异常，即父级方法必须无事务 实现跨库事务前提：事务都是跟着数据库连接走的，一个@Transactional只能控制一个数据库的事务，所以一个事务方法内操作多个库的话，只有一个库事务启作用 有两个注意点： 一个事务里涉及到多个库，一定要使用嵌套方法调用，每个方法都加@Transactional，每个方法操作一个库，比如A调B，B调C，C调D，这样每个方法（事务）都会等下一个方法（事务）处理完才能提交，如果有一个方法（事务）异常，则全部回滚 不能A调完B再调C，这样B方法执行完，如果没有异常直接提交了，那A方法后边的逻辑异常了，B是不会回滚的，所以第二点需要注意的是，嵌套调用时，调用方法后不能有任何逻辑，否则，主方法异常后，子方法不能回滚 场景1： 123456@Transactional(&quot;库A&quot;)public void serviceA()&#123; //库A-表1 //库A-表2 //库B-表1&#125; 如果跨两个库，可以不用嵌套事务，一个事务就可以，因为库A的事务等执行完整个方法才提交，所以库B成功，则库A也提交，库B失败，则库A也回滚，但库B后边不能有任何逻辑，参考第二注意点 场景2： 12345678910111213141516@Transactional(&quot;库A&quot;)public void serviceA()&#123; //库A-表1 //库A-表2 serviceB();&#125;@Transactional(&quot;库B&quot;)public void serviceB()&#123; //库B-表1 serviceC();&#125;@Transactional(&quot;库C&quot;)public void serviceC()&#123; //库C-表1&#125; 涉及3个以上的库，嵌套调用，如果serviceB异常，serviceA还没提交，还在等serviceB执行，捕捉到serviceB异常后，回滚，同理serviceC异常，serviceA等serviceB，serviceB等serviceC，捕获到异常后都回滚。 注意：抛RuntimeException，或者注解中指定异常类型"},{"title":"一次系统启动失败经历","path":"/2020/05/09/一次系统启动失败经历/","content":"最近遇到一个很头疼的问题，在一次合代码后，系统启不来了，确切的说，本地可以起来，生成容器镜像后启不来，报了一大堆创建Spring bean异常，本地能启动，镜像启不来，这是不是很怀疑人生，通过各种排除法手段合并代码、删除代码，但就是不行，第二天又重新倒腾了一下（merge），好了，也不知道为啥就好了。 接着又有新需求了，从master上拉新的分支，吭哧吭哧干完了，编译、打包、生成镜像、部署、启动，完，又出现那个熟悉的异常了，我始终都相信代码不会说谎，绝不会是偶然，所以我决定好好找找原因。 123Related cause: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#x27;meteringLastBillingRecordMapper&#x27; defined in URL [jar:file:/export/Packages/jcloud-newbilling/feature-settlement-info-add-fee-20200423-c4b21536-0423144327/webapps/ROOT/WEB-INF/lib/billing-dao-1.0-SNAPSHOT.jar!/com/jcloud/billing/mapper_metering/MeteringLastBillingRecordMapper.class]: Cannot resolve reference to bean &#x27;meteringSqlSessionFactory&#x27; while setting bean property &#x27;sqlSessionFactory&#x27;; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#x27;meteringSqlSessionFactory&#x27;: FactoryBean threw exception on object creation; nested exception is java.lang.IllegalArgumentException: Property &#x27;dataSource&#x27; is requiredRelated cause: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#x27;meteringOverViewMapper&#x27; defined in URL [jar:file:/export/Packages/jcloud-newbilling/feature-settlement-info-add-fee-20200423-c4b21536-0423144327/webapps/ROOT/WEB-INF/lib/billing-dao-1.0-SNAPSHOT.jar!/com/jcloud/billing/mapper_metering/MeteringOverViewMapper.class]: Cannot resolve reference to bean &#x27;meteringSqlSessionFactory&#x27; while setting bean property &#x27;sqlSessionFactory&#x27;; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#x27;meteringSqlSessionFactory&#x27;: FactoryBean threw exception on object creation; nested exception is java.lang.IllegalArgumentException: Property &#x27;dataSource&#x27; is required 观察异常信息后，都是创建bean的错误，前提是所有的bean都被扫描到了，有一个现象是本地虽然能起来，但日志里也有WARN信息，信息也是关于创建bean的，决定升级下Spring试试，从4.3.2-&gt;5.2.5，完事后镜像启动，还是报错； 再观察异常信息后，发现最后都是以sharding-JDBC相关的持久层mapper结束的，所以从sharding-JDBC数据源的xml开始，把原来的配置文件备份下，重新搞一个新的，并且跟官方的shardingsphere-example对比，写完后，再镜像启动，还是报错； 再看shardingsphere-example后，持久层是用@Mapper注解，项目工程是用@Repository注解，难道是这个问题吗？到了这个份上，可能你觉得什么都有可能是错的，那就试一下吧，持久层注解改成@Mapper，咦？没有这个注解，项目工程的mybatis包版本是3.2.5，版本低，还没有这个注解，那就升下级，升级到3.4.2，顺便把mybatis-spring也升下级，1.2.1-&gt;1.3.0，完事后镜像启动，好了，很鸡冻。 此时由恍惚变得清醒了点，其实跟注解是@Mapper没啥关系，主要还是很mybatis、mybatis-spring版本低有关，重新把@Mapper换成@Repository后，镜像启动，也没毛病。 所以最终还是mybatis、mybatis-spring的版本和spring的版本不匹配导致，至于在本地启动可以，在镜像启动不行，这个问题还是无解，可能是跟环境有关"},{"title":"Sharding JDBC生产问题","path":"/2020/04/10/Sharding-JDBC/","content":"最近项目中在使用数据库中间件，采用ShardingSphere中的Sharding-JDBC，总结下最近出现的问题 ShardingSphere官网 分布式主键重复问题问题描述告警双写失败，库中新增metering和last_billing_record违反唯一主键约束 问题分析因为涉及到分库分表，数据是分散存放的，为了避免分表中的主键不重复，所以使用分布式主键算法生成主键，目前使用的是Sharding内置的SnowFlake(Twitter开源的)算法SnowFlake算法生成ID的结构如下图： 其中工作机器id(workerId)是用来区分不同的机器而设计，上线时，未设置这个参数，默认为0，也就是线上8台服务的workerId都为0，这样就会出现某几台服务器在同一时间(毫秒)写同一张表，按照原理图可以得出时间戳一样，工作机器id一样，序列号一样，所以就出现了多台服务器同一时间用同一个主键id写表，报了违反唯一主键约束的错误 基于计费的业务特殊性，0-半点之间会跑分布式任务，所以很容易造成多台服务器同一时间写同一张表的情况 解决方案为每台服务器设置单独的workerId，workerId取值范围0-1023 Spring Sharding配置文件是支持注入worker.id值的，但只能在配置文件配置，不能动态生成，最终会部署到8台服务器上，读的还是一个值，咨询过Sharding创始人，也没有扩展接口可以重写workerId的值 起初想过通过云翼的外挂配置文件important.properties设置workerId值，Spring配置文件再读取important.properties设置的值，不行，因为云翼上是按照az外挂的，每个az有两台服务器，那这两台服务器读取的还是一个值，还是会出现问题 最后是通过实现Spring IOC容器给我们提供的一个扩展接口BeanPostProcessor实现的，BeanPostProcessor提供了一个postProcessBeforeInitialization方法，也就是在bean初始化前可以修改worker.id的值，这样就可以为所欲为了，最终是用redis为每个服务器ip生成自增的序列值，存到redis里，每次启动时根据键ip读取redis的值，以后扩容机器接着申请即可 时钟回拨问题问题描述邮件告警双写失败，Cause: java.lang.IllegalStateException: Clock is moving backwards, last time is %d milliseconds, current time is %d milliseconds [1584000400088, 1584000399959] 问题分析错误信息中Clock is moving backwards，是由于时钟回退导致，当前生成id的时间早于最后一次生成id的时间 SnowFlake生成规则依赖时间戳，这样由于时间校准，以及其他因素，可能导致服务器时间回退（时间向前快进不会有问题），如果恰巧回退前生成过一些id，而时间回退后，生成的id就有可能重复。官方对于此并没有给出解决方案，而是简单的抛错处理，这样会造成在时间被追回之前的这段时间服务不可用 恰好10.160.10.50容器的时间比其他容器的时间快1-2s，每隔一段时间发生一次时间校准，在时间校准前后都发生了insert操作，导致了当前生成id的时间早于最后一次生成id的时间，框架报错，insert失败 解决方案 代码方面 Sharding提供了一个扩展接口ShardingKeyGenerator，可以自己实现一套分布式id生成算法，这里只是在内置的SnowFlake基础上改进了时钟回拨导致服务不可用的问题 SnowFlake算法给workerId预留了10位，即workerId的取值范围为[0, 1023]，事实上实际生产环境不大可能需要部署1024个服务 所以采用备用workerId的方式，举例：将workerId取值范围缩小为[0, 511]，[512, 1023]这个范围的workerId当做备用workerId。workerId为0的备用workerId是512，workerId为1的备用workerId是513，以此类推…… 备用workerId数量越多, 可靠性越高, 但是可部署的服务就越少 目前计费是设置了7个备份，最多能部署128个节点，足够用了 这样改后，虽然解决了不可用问题，但频繁的时钟回退导致主键不具备递增特性，根据MySql聚集索引的特性，如果主不是递增，会导致索引数据结构(B+Tree)频繁的进行分裂和平衡，随着数据量越大，性能损耗越严重 硬件方面 10.160.10.50容器迁移到了时钟正常的物理机上 多线程并发时路由不准确问题问题描述告警双写失败，更新metering或者last_billing_record条数为0，未更新成功 问题分析通过查日志发现，同一台服务器上的两个线程操作同一张表时，路由会混乱，a线程会使用b线程的路由分片值 a线程做数据迁移，迁移的时间2019-03-14 - 2019-03-31 b线程处理Kafka消息，生成用量数据，时间是2020-03-17 两个线程并发时，a线程会使用b线程的路由分片值，这样就导致a线程先用路由分片值2019-03-17插入表metering_1903成功，再用路由值2020-03-17更新表metering_2003的状态，两个表不一致，导致更新不到数据 Spring注入的路由实现类是单例的，为了方便取值，路由实现类将路由分片值定义成了实例变量，如果单例中使用实例变量，多线程不安全 解决方案删除实例变量，路由值通过方法参数传递，或者Spring注入实例设置为多例"},{"title":"Slf4j MDC 实现日志追踪","path":"/2020/04/09/log-mdc/","content":"背景随着项目的越来越大，应用处理用户请求越来越多的时候，查日志是个头疼的事，因为你要去海量日志里追踪某个用户的相关日志记录时，非常麻烦；刚开始用线程名称找，线程池的线程很快就被复用，还是很难区分，MDC就可以解决这个问题。 什么是MDCMDC（Mapped Diagnostic Context，映射调试上下文） 概括一下： MDC是一个与当前线程绑定的哈希表，可以往其中添加键值对 MDC中包含的内容可以被同一线程中执行的代码所访问 当前线程的子线程会继承其父线程中的MDC的内容，当需要记录日志时，只需要从MDC中获取所需的信息即可 MDC的内容则由程序在适当的时候保存进去。对于一个Web应用来说，通常是在请求被处理的最开始保存这些数据 web项目用法对于一个正在迭代的工程来说，肯定对代码的侵入越小越好，结合代码来看看怎么用 定义一个键值对，比如key是traceId，值是上游请求带过来的，如果没带过来，则新生成一个UUID代替，当然要根据你的实际情况定义有实际意义业务上的字段 在拦截web请求的preHandle回调方法里保存这个键值对 123456789@Overridepublic boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) &#123; String traceId = request.getHeader(&quot;traceId&quot;); if (StringUtils.isBlank(traceId)) &#123; traceId = &quot;s-&quot; + UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;).toLowerCase(); &#125; MDC.put(&quot;traceId&quot;, traceId); return true; &#125; 在整个请求处理完毕afterCompletion回调方法里清除键值对，为什么要清除，因为线程池的线程是可以复用的，如果不清除，下次复用处理其他请求时，还会打印相同的traceId，就会产生混淆 1234@Override public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) &#123; MDC.clear(); &#125; 最后一步，在log4j的xml文件里把%X&#123;traceId&#125;加到你想要打印的位置 1&lt;PatternLayout charset=&quot;UTF-8&quot; pattern=&quot;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%t] %X&#123;traceId&#125; %-5level %C.%M %L - %m%n&quot;/&gt; 如果新启了子线程，在子线程中MDC.get(“traceId”)就可以取到父线程设置的值 定时任务用法如果你有定时任务在跑，而且还有很多，同样，加上MDC，只需要通过Spring AOP定义一个拦截器，然后在Spring配置文件中定义切点和切面即可 123456789public class TaskLog4jAdvice implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; MDC.put(&quot;traceId&quot;, &quot;s-&quot; + UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;).toLowerCase()); Object object = invocation.proceed(); MDC.clear(); return object; &#125;&#125; 12345678&lt;aop:aspectj-autoproxy /&gt; &lt;bean id=&quot;taskLog4jAdvice&quot; class=&quot;com.wurimo.common.advice.TaskLog4jAdvice&quot;/&gt; &lt;aop:config&gt; &lt;aop:advisor id=&quot;taskMethodLog&quot; advice-ref=&quot;taskLog4jAdvice&quot; pointcut=&quot; (execution(* com.wurimo.*.task.*.*(..))) &quot;/&gt; &lt;/aop:config&gt; 多线程场景用法当创建子线程的时候，我们期望子线程一样可以使用MDC的信息来实现日志追踪，先通过MDC.getCopyOfContextMap()方法将MDC内存获取出来，并在子线程的执行最开始调用MDC.setContextMap(context)方法将父线程的MDC内容传给子线程，执行结束后调用clear清空。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100package com.surimo.common.log4j;import org.slf4j.MDC;import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;import java.util.Map;import java.util.concurrent.Callable;import java.util.concurrent.Future;public class MdcThreadPoolTaskExecutor extends ThreadPoolTaskExecutor &#123; private static final long serialVersionUID = 1L; private boolean useFixedContext = false; private Map&lt;String, String&gt; fixedContext; public MdcThreadPoolTaskExecutor() &#123; super(); &#125; public MdcThreadPoolTaskExecutor(Map&lt;String, String&gt; fixedContext) &#123; super(); this.fixedContext = fixedContext; useFixedContext = (fixedContext != null); &#125; private Map&lt;String, String&gt; getContextForTask() &#123; return useFixedContext ? fixedContext : MDC.getCopyOfContextMap(); &#125; @Override public void execute(Runnable task, long startTimeout) &#123; this.execute(task); &#125; @Override public Future&lt;?&gt; submit(Runnable task) &#123; return super.submit(wrapSubmit(task, getContextForTask())); &#125; @Override public void execute(Runnable task) &#123; super.execute(wrapExecute(task, getContextForTask())); &#125; @Override public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; return super.submit(wrapSubmit(task, getContextForTask())); &#125; private &lt;T&gt; Callable&lt;T&gt; wrapSubmit(final Callable&lt;T&gt; task, final Map&lt;String, String&gt; context) &#123; return new Callable&lt;T&gt;() &#123; @Override public T call() throws Exception &#123; Map&lt;String, String&gt; previous = MDC.getCopyOfContextMap(); if (context == null) &#123; MDC.clear(); &#125; else &#123; MDC.setContextMap(context); &#125; try &#123; return task.call(); &#125; finally &#123; if (previous == null) &#123; MDC.clear(); &#125; else &#123; MDC.setContextMap(previous); &#125; &#125; &#125; &#125;; &#125; private Runnable wrapSubmit(final Runnable runnable, final Map&lt;String, String&gt; context) &#123; return this.wrapExecute(runnable, context); &#125; private Runnable wrapExecute(final Runnable runnable, final Map&lt;String, String&gt; context) &#123; return new Runnable() &#123; @Override public void run() &#123; Map&lt;String, String&gt; previous = MDC.getCopyOfContextMap(); if (context == null) &#123; MDC.clear(); &#125; else &#123; MDC.setContextMap(context); &#125; try &#123; runnable.run(); &#125; finally &#123; if (previous == null) &#123; MDC.clear(); &#125; else &#123; MDC.setContextMap(previous); &#125; &#125; &#125; &#125;; &#125;&#125; 新开线程用法当我们随时都想开启一个新线程处理异步流程时，当然也少不了日志追踪，举个栗子，发通知邮件，定一个抽象类实现Runnable： 1234567891011121314151617181920212223242526272829package com.wurimo.common.mdc;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.slf4j.MDC;import java.util.Map;public abstract class MdcRunnable implements Runnable &#123; private final static Logger logger = LoggerFactory.getLogger(MdcRunnable.class); private final Map&lt;String, String&gt; mdcContext = MDC.getCopyOfContextMap(); @Override public void run() &#123; try &#123; if (mdcContext != null) &#123; MDC.setContextMap(mdcContext); &#125; process(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; finally &#123; MDC.clear(); &#125; &#125; public abstract void process();&#125; 继承后处理自己的业务逻辑： 1234567class EmailProcess extends MdcRunnable &#123; @Override public void process() &#123; //TODO &#125; &#125; MDC原理MDC实现多线程下区分不同信息就是通过ThreadLocal，我们放进去的键值对最终定义在这里：private final ThreadLocal&lt;Map&lt;String, String&gt;&gt; localMap;MDC.put时： 12345678910@Overridepublic void put(final String key, final String value) &#123; if (!useMap) &#123; return; &#125; Map&lt;String, String&gt; map = localMap.get(); map = map == null ? new HashMap&lt;String, String&gt;() : new HashMap&lt;String, String&gt;(map); map.put(key, value); localMap.set(Collections.unmodifiableMap(map));&#125; MDC.get时： 12345@Overridepublic String get(final String key) &#123; final Map&lt;String, String&gt; map = localMap.get(); return map == null ? null : map.get(key);&#125; MDC.clear时： 1234567891011121314@Overridepublic void clear() &#123; localMap.remove();&#125;@Overridepublic void remove(final String key) &#123; final Map&lt;String, String&gt; map = localMap.get(); if (map != null) &#123; final Map&lt;String, String&gt; copy = new HashMap&lt;String, String&gt;(map); copy.remove(key); localMap.set(Collections.unmodifiableMap(copy)); &#125;&#125; 有兴趣可以自行看下源码https://hexo.io/docs/one-command-deployment.html)"},{"title":"Hibernate Validator 参数校验","path":"/2020/04/09/Hibernate-Validator/","content":"背景在任何时候，当你要处理一个应用程序的业务逻辑，数据校验是你必须要考虑和面对的事情。应用程序必须通过某种手段来确保输入进来的数据从语义上来讲是正确的。在通常的情况下，应用程序是分层的，不同的层由不同的开发人员来完成。很多时候同样的数据验证逻辑会出现在不同的层，这样就会导致代码冗余和一些管理的问题，比如说语义的一致性等。为了避免这样的情况发生，最好是将验证逻辑与相应的域模型进行绑定。 以上摘自https://www.ibm.com/developerworks/cn/java/j-lo-jsr303/index.html，还有一些更具体的介绍 Hibernate Validator简介Hibernate Validator实现了JSR-303规范,Hibernate Validator是Bean Validation的参考实现，Hibernate Validator提供了JSR-303规范所有内置的约束，并额外附加了一些约束。 新版本会不断有新的附加约束，不限于以下，以最新的版本为主 Bean Validation 中的 constraint Constraint 详细信息 @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max, min) 被注释的元素的大小必须在指定的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(value) 被注释的元素必须符合指定的正则表达式 @Negative 被注释的元素必须是负数 @NegativeOrZero 被注释的元素必须是负数或零 @Positive 被注释的元素必须是正数 @PositiveOrZero 被注释的元素必须是正数或零 Hibernate Validator 附加的 constraint Constraint 详细信息 @CreditCardNumber 被注释的元素必须是合法的信用卡号码 @Email 被注释的元素必须是电子邮箱地址 @Length 被注释的字符串的大小必须在指定的范围内 @NotBlank 被注释的字符串的必须非空 @NotEmpty 被注释的字符串的必须非空 @Range 被注释的元素必须在合适的范围内 @SafeHtml 被注释的元素可能有不安全的HTML内容 @ScriptAssert 被注释的元素执行脚本表达式”{script}”没有返回期望结果 @URL 被注释的元素必须是一个合法的URL Hibernate Validator使用以Spring MVC为例 maven引入jar包，按照自己的实际需要可以引入其他版本12345&lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;version&gt;5.2.4.Final&lt;/version&gt;&lt;/dependency&gt; spring-mvc.xml主要的配置123456789101112131415&lt;mvc:annotation-driven validator=&quot;validator&quot;/&gt;&lt;bean id=&quot;validator&quot; class=&quot;org.springframework.validation.beanvalidation.LocalValidatorFactoryBean&quot;&gt; &lt;property name=&quot;providerClass&quot; value=&quot;org.hibernate.validator.HibernateValidator&quot;/&gt; &lt;property name=&quot;validationMessageSource&quot; ref=&quot;validatorMessageSource&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;validatorMessageSource&quot; class=&quot;org.springframework.context.support.ResourceBundleMessageSource&quot;&gt; &lt;property name=&quot;basenames&quot;&gt; &lt;list&gt; &lt;value&gt;org.hibernate.validator.ValidationMessages&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=&quot;defaultEncoding&quot; value=&quot;UTF-8&quot;/&gt;&lt;/bean&gt; 请求参数@RequestParam校验在@RequestParam前加相应的约束就可以，比如@NotBlank、@Length，message可以设置提示语 1234567@RequestMapping(value = &quot;/sendBusinessJmq&quot;, method = &#123;RequestMethod.GET, RequestMethod.POST&#125;, produces = &quot;application/json;charset=utf-8&quot;)@ResponseBodypublic Object sendBusinessJmq(@NotBlank(message = &quot;单号不能为空&quot;) @RequestParam(&quot;settlementNo&quot;) final String settlementNo, @NotBlank(message = &quot;状态不能为空&quot;) @Length(max = 2, message = &quot;长度不能超过2&quot;) @RequestParam(&quot;status&quot;) final int status) &#123; //TODO return &quot;success&quot;;&#125; 请求参数@RequestBody校验在@RequestBody加上@Validated就可以对后边的model参数进行校验了，model会对具体的字段做校验，下面会写 网上说需要在Controller上加@Validated，自己试过不加也可以 12345@PostMapping(&quot;/systemConfig/add&quot;)public Object settleObjectTypeAdd(HttpServletRequest request, @RequestBody @Validated SystemConfigVo vo) &#123; //TODO return &quot;success&quot;;&#125; model校验在每个字段上加相应的约束就可以了 注意：Long类型上要加@NotNull，不要加@NotBlank，如果碰到下面这个异常就是这个问题：javax.validation.UnexpectedTypeException: HV000030: No validator could be found for constraint ‘org.hibernate.validator.constraints.NotBlank’ validating type ‘java.lang.Long’. Check configuration for ‘id’ 12345678910111213141516@Datapublic class SystemConfigVo &#123; @NotNull(message = &quot;id不能为null&quot;) private Long id; @NotBlank @Length(min = 1, max = 20) private String key; @NotBlank @Length(min = 1, max = 50, message = &quot;长度需要在1-50之间&quot;) private String desc;&#125; 对象嵌套校验有的时候，入参的对象可能包含List，或者对象包含其他model，同时也要对嵌套的对象进行校验Controller代码： 12345@PostMapping(&quot;/settlementObject/operation:add&quot;)public Object operationAdd(HttpServletRequest request, @RequestBody @Validated SettlementObjectListVo listVo) &#123; //TODO return &quot;success&quot;;&#125; SettlementObjectListVo代码：嵌套的对象上要加@Valid，就可以对SettlementObjectVo的字段进行校验了 12345678@Datapublic class SettlementObjectListVo &#123; private String regionId; @Valid private List&lt;SettlementObjectVo&gt; settlementObjectList;&#125; SettlementObjectVo代码： 123456789101112131415161718192021222324@Datapublic class SettlementObjectVo implements Serializable &#123; private static final long serialVersionUID = 6063724154195494666L; @Email @Length(max = 50) private String email; @Length(min = 1, max = 20) private String businessErp; @NotNull @Range(min = 1, max = 5) private Byte settlementCycle; @NotBlank @Length(min = 1, max = 40) private String bankCompanyName; @NotBlank @Length(min = 1, max = 30) @Pattern(regexp = &quot;[0-9]*$&quot;, message = &quot;必须是数字&quot;) private String bankCardNo;&#125; 分组校验有这样一种场景，新增系统配置信息的时候，不需要验证id（因为系统生成）；修改的时候需要验证id，这时候就用到validator的分组验证功能定义分组： 12345public interface Add &#123;&#125;public interface Modify &#123;&#125; model代码：增加groups属性，id在修改的时候才去校验，key是增加和修改的时候都去校验，desc增加的时候校验不能为空，修改的时候校验长度 12345678910111213141516@Datapublic class SystemConfigVo &#123; @NotNull(groups = &#123;Modify.class&#125;) private Long id; @NotBlank(groups = &#123;Modify.class, Add.class&#125;) @Length(max = 20, groups = &#123;Modify.class, Add.class&#125;) private String key; @NotBlank(groups = &#123;Add.class&#125;) @Length(max = 50, groups = &#123;Modify.class, Add.class&#125;) private String desc;&#125; Controller代码：@Validated增加Add.class去校验SystemConfigVo的时候只校验设置Add.class分组的字段，比如上面的key和desc 12345@PostMapping(&quot;/systemConfig/add&quot;)public Object costTypeAdd(HttpServletRequest request, @RequestBody @Validated(&#123;Add.class&#125;) SystemConfigVo vo) &#123; //TODO return &quot;success&quot;;&#125; 请求参数List类型校验适合入参有List集合的参数，需要定义一个ValidList，里面的list上要加@Valid；Controller方法入参类型由原来的List改为ValidListValidList代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128public class ValidList&lt;E&gt; implements List&lt;E&gt; &#123; @Valid private List&lt;E&gt; list = new LinkedList&lt;&gt;(); public List&lt;E&gt; getList() &#123; return list; &#125; public void setList(List&lt;E&gt; list) &#123; this.list = list; &#125; @Override public int size() &#123; return list.size(); &#125; @Override public boolean isEmpty() &#123; return list.isEmpty(); &#125; @Override public boolean contains(Object o) &#123; return list.contains(o); &#125; @Override public Iterator&lt;E&gt; iterator() &#123; return list.iterator(); &#125; @Override public Object[] toArray() &#123; return list.toArray(); &#125; @Override public &lt;T&gt; T[] toArray(T[] a) &#123; return list.toArray(a); &#125; @Override public boolean add(E e) &#123; return list.add(e); &#125; @Override public boolean remove(Object o) &#123; return list.remove(o); &#125; @Override public boolean containsAll(Collection&lt;?&gt; c) &#123; return list.containsAll(c); &#125; @Override public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return list.addAll(c); &#125; @Override public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; return list.addAll(index, c); &#125; @Override public boolean removeAll(Collection&lt;?&gt; c) &#123; return list.removeAll(c); &#125; @Override public boolean retainAll(Collection&lt;?&gt; c) &#123; return list.retainAll(c); &#125; @Override public void clear() &#123; list.clear(); &#125; @Override public E get(int index) &#123; return list.get(index); &#125; @Override public E set(int index, E element) &#123; return list.set(index, element); &#125; @Override public void add(int index, E element) &#123; list.add(index, element); &#125; @Override public E remove(int index) &#123; return list.remove(index); &#125; @Override public int indexOf(Object o) &#123; return list.indexOf(o); &#125; @Override public int lastIndexOf(Object o) &#123; return list.lastIndexOf(o); &#125; @Override public ListIterator&lt;E&gt; listIterator() &#123; return list.listIterator(); &#125; @Override public ListIterator&lt;E&gt; listIterator(int index) &#123; return list.listIterator(index); &#125; @Override public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; return list.subList(fromIndex, toIndex); &#125;&#125; Controller代码： 12345@PostMapping(&quot;/systemConfig/add&quot;)public Object costTypeAdd(HttpServletRequest request, @RequestBody @ValidList&lt;SystemConfigVo&gt; listVo) &#123; //TODO return &quot;success&quot;;&#125; 自定义校验自带的约束可能满足不了自己的业务校验规则，可以自定义一个，比如定义一个输入的值是否在指定范围的注解定义注解： 12345678910111213@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.FIELD, ElementType.PARAMETER&#125;)@Constraint(validatedBy = FlagValidatorClass.class)public @interface FlagValidator &#123; String[] value() default &#123;&#125;; String message() default &quot;flag is not found&quot;; Class&lt;?&gt;[] groups() default &#123;&#125;; Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;;&#125; 定义一个校验器，具体校验规则： 123456789101112131415161718192021public class FlagValidatorClass implements ConstraintValidator&lt;FlagValidator, Integer&gt; &#123; private String[] values; @Override public void initialize(FlagValidator flagValidator) &#123; this.values = flagValidator.value(); &#125; @Override public boolean isValid(Integer value, ConstraintValidatorContext constraintValidatorContext) &#123; if (value == null) &#123; return true; &#125; for (String v : values) &#123; if (v.equals(String.valueOf(value))) &#123; return true; &#125; &#125; return false; &#125;&#125; 字段上设置刚自定义的校验注解，如果输入的不在这5个其中的一个会提示状态有误 12@FlagValidator(value = &#123;&quot;-1&quot;, &quot;4&quot;, &quot;5&quot;, &quot;7&quot;, &quot;12&quot;&#125;, message = &quot;状态有误&quot;)private Integer status; 校验错误提示信息上面看到的约束都没配置提示信息，没配置用的是Hibernate Validator自带的配置，默认是英文提示，如下： 12@NotNull(groups = &#123;Modify.class&#125;)private Long id; 默认的配置在包里，如下： 也可以配置自己想要的提示语，增加message属性 12@NotNull(groups = &#123;Modify.class&#125;, message = &quot;id不能为null&quot;)private Long id; 提示语也可以统一到配置文件message.properties中，如下： 12@NotNull(groups = &#123;Modify.class&#125;, message = &quot;&#123;id.NotNull.message&#125;&quot;)private Long id; message.properties如下： 12345id.NotNull.message = id不能为nullkey.NotBlank.message = 编码不能为空key.Length.message = 编码长度不能超过&#123;max&#125;desc.NotBlank.message = 名称不能为空desc.Length.message = 名称长度不能超过&#123;max&#125; 异常统一处理在全局异常拦截中添加验证异常的处理： 1234567891011121314@ExceptionHandler(MethodArgumentNotValidException.class)@ResponseBodypublic OpenApiResponse methodArgumentNotValid(HttpServletRequest request, MethodArgumentNotValidException e) &#123; logger.error(&quot;enter MethodArgumentNotValidException&quot;); BindingResult bindingResult = e.getBindingResult(); Map&lt;String, String&gt; messageMap = new HashMap&lt;&gt;(); for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; messageMap.put(String.valueOf(fieldError.getRejectedValue()), fieldError.getDefaultMessage()); &#125; String message = JSON.toJSONString(messageMap); logger.error(message); return response(request, message); &#125; 返回的提示语类似这样： 提示消息国际化国际化的配置在上面spring-mvc.xml已经配置过了 12345678&lt;bean id=&quot;validatorMessageSource&quot; class=&quot;org.springframework.context.support.ResourceBundleMessageSource&quot;&gt; &lt;property name=&quot;basenames&quot;&gt; &lt;list&gt; &lt;value&gt;org.hibernate.validator.ValidationMessages&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=&quot;defaultEncoding&quot; value=&quot;UTF-8&quot;/&gt;&lt;/bean&gt; org.hibernate.validator.ValidationMessages我配置的是Hibernate Validator自带的国际化配置文件，配置后默认就是中文啦； 也可以自定义配置文件，在工程的resource下定义i18n&#x2F;message_zh_CN.propertiesorg.hibernate.validator.ValidationMessages改为i18n.message即可 解释 名词 解释 JCP Java Community Process，Java社区 JSR Java Specification Requests，Java规范提案。是指向JCP提出新增一个标准化技术规范的正式请求，认识人都可以提交JSR，以向Java平台增添新的API和服务 JSR-303 JAVA EE 6 中的一项子规范，叫做Bean Validation"},{"title":"Windows剪贴板增强软件-ClipX","path":"/2020/04/09/Windows剪贴板增强软件-ClipX/","content":"效率神器-只限windows官网下载：http://bluemars.org/clipx/ 能干啥ClipX可以保存最近多次复制的内容，重复的内容不用来回复制了，支持文本、图片，而且复制的内容可以保存再本地，电脑重启后还能用 使用，图标右键 扩充剪贴板数量最多支持保存1024条记录，正常人够用了 随时预览剪贴板内容 可以编辑剪贴板内容 数据本地存储还得手动，自动存储就好了 快捷键设置 优点 免费 内存占用低 简单易用 侵入性小，不影响系统自带剪贴板 支持插件扩展"},{"title":"APM-Pinpoint","path":"/2020/04/09/APM-Pinpoint/","content":"架构图 单机模式安装准备安装包： Hbase hbase-2.1.5-bin.tar.gz hbase-create.hbase下载地址：http://apache.fayea.com/hbase/wget http://apache.fayea.com/hbase/2.1.5/hbase-2.1.5-bin.tar.gzhttps://github.com/naver/pinpoint/tree/master/hbase/scripts/hbase-create.hbase pinpoint pinpoint-collector-1.8.4.war pinpoint-web-1.8.4.war pinpoint-agent-1.8.4.tar.gz下载地址：https://github.com/naver/pinpoint/releases 安装Hbase1、解压hbase-2.1.5-bin.tar.gz 1tar xf hbase-2.1.5-bin.tar.gz 2、启动 12cd hbase-2.1.5/bin./start-hbase.sh 需要jdk8版本，手动指定jdk配置：cd hbase-2.1.5&#x2F;confvim hbase-env.sh增加export JAVA_HOME&#x3D;&#x2F;export&#x2F;software&#x2F;jdk1.8.0_20&#x2F;保存后启动 3、初始化脚本 1./hbase shell /home/ssh/pinpoint/hbase-create.hbase 4、web访问http://127.0.0.1:16010/ 安装pinpoint-collector解压war包到tomcat下 123unzip pinpoint-collector-1.8.4.war -d /home/ssh/pinpoint/tomcat-collector/webapps/ROOTcd /home/ssh/pinpoint/tomcat-collector/bin./startup.sh 安装pinpoint-web解压war包到tomcat下（端口号28080） 123unzip pinpoint-web-1.8.4.war -d /home/ssh/pinpoint/tomcat-web/webapps/ROOTcd /home/ssh/pinpoint/tomcat-web/bin./startup.sh 注意修改tomcat端口号 web访问：http://127.0.0.1:28080/ 安装pinpoint-agent tomcat启动的应用在tomcat bin下的catalina.sh增加配置 123CATALINA_OPTS=&quot;$CATALINA_OPTS -javaagent:/export/software/pinpoint/agent/pinpoint-bootstrap-1.8.4.jar&quot;CATALINA_OPTS=&quot;$CATALINA_OPTS -Dpinpoint.agentId=settlment1&quot;CATALINA_OPTS=&quot;$CATALINA_OPTS -Dpinpoint.applicationName=settlement&quot; springboot启动的应用jar启动方式为： 1nohup java -javaagent:/home/ssh/software/pinpoint/agent/pinpoint-bootstrap-1.8.4.jar -Dpinpoint.applicationName=settlement -Dpinpoint.agentId=settlement1 -jar settlement-latest.jar &gt;/dev/null 2&gt;&amp;1 &amp; 使用手册https://blog.csdn.net/xvshu/article/details/79866237 参考https://www.jianshu.com/p/a803571cd570"},{"title":"redis分布式锁","path":"/2020/04/09/redis分布式锁/","content":"加锁伪代码 123456789101112private static final String LOCK_SUCCESS = &quot;OK&quot;;public boolean acquireLock(String lockKey, String value) &#123; logger.info(&quot;acquireLock lockKey:&#123;&#125;, value:&#123;&#125;&quot;, lockKey, value); //NX是不存在时才set， XX是存在时才set， EX是秒，PX是毫秒 String result = jedis.set(key, value, &quot;NX&quot;, &quot;PX&quot;, LOCK_TIMEOUT); boolean flag = false; if(LOCK_SUCCESS.equals(result))&#123; flag = true; &#125; logger.info(&quot;acquireLock result:&quot; + flag); return flag; &#125; 第一个为key，我们使用key来当锁名第二个为value，我们传的是uid，唯一随机数，也可以使用本机mac地址 + uuid第三个为NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作第四个为PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定第五个为time，代表key的过期时间，对应第四个参数 PX毫秒，EX秒 释放锁伪代码 123456789101112private static final Long RELEASE_LOCK_SUCCESS = 1L;public boolean releaseLock(String lockKey, String value) &#123; logger.info(&quot;releaseLock lockKey:&#123;&#125;, value:&#123;&#125;&quot;, lockKey, value); String luaScript = &quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(value)); boolean flag = false; if(RELEASE_LOCK_SUCCESS.equals(result))&#123; flag = true; &#125; logger.info(&quot;releaseLock result:&quot; + flag); return flag; &#125; redis可以保证lua中的键的原子操作上边lua脚本的意思：if redis.call(&quot;get&quot;,&quot;“ + lock + “&quot;) &#x2F;&#x2F; redisGET命令 &#x3D;&#x3D; &quot;“ +uid + &#x2F;&#x2F; 判断是否是当前线程 “&quot;then return redis.call(&quot;del&quot;,&quot;“ + lock + “&quot;) &#x2F;&#x2F; 如果是，执行redis DEL操作，删除锁 else return 0 end 关于luaLua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。Lua 提供了交互式编程模式。我们可以在命令行中输入程序并立即查看效果。 lua脚本优点 减少网络开销：本来多次网络请求的操作，可以用一个请求完成，原先多次请求的逻辑放在redis服务器上完成。使用脚本，减少了网络往返时延 原子操作：Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入 复用：客户端发送的脚本会永久存储在Redis中，意味着其他客户端可以复用这一脚本而不需要使用代码完成同样的逻辑"},{"title":"APM-Skywalking","path":"/2020/04/09/APM-Skywalking/","content":"简介官网：http://skywalking.apache.org/zh/ 安装：https://github.com/apache/skywalking/blob/5.x/docs/README_ZH.md mysql版本安装：https://blog.csdn.net/sinat_30126855/article/details/100895591 查看效果：http://blog.wurimo.com:8070/ 对比：https://www.jianshu.com/p/0fbbf99a236e 安装es：https://www.jianshu.com/p/c5347f502205https://www.jianshu.com/p/e3d7c50651f6https://www.jianshu.com/p/a803571cd570)"}]